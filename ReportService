package com.fincore.ReportService.advice;

import org.springframework.core.MethodParameter;
import org.springframework.core.annotation.AnnotatedElementUtils;
import org.springframework.http.MediaType;
import org.springframework.http.ResponseEntity;
import org.springframework.http.converter.HttpMessageConverter;
import org.springframework.http.server.ServerHttpRequest;
import org.springframework.http.server.ServerHttpResponse;
import org.springframework.web.bind.annotation.ControllerAdvice;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.web.servlet.mvc.method.annotation.ResponseBodyAdvice;
import com.fincore.ReportService.dto.ApiResponse;


/**
 * This ControllerAdvice intercepts successful responses from any @RestController
 * and wraps them in a standard ApiResponse format.
 */
@ControllerAdvice
public class ApiResponseWrapper implements ResponseBodyAdvice<Object> {

    @Override
    public boolean supports(MethodParameter returnType, Class<? extends HttpMessageConverter<?>> converterType) {
        // This advice applies to any method in a class annotated with @RestController
        // that is not already returning a ResponseEntity (which gives manual control).
        return AnnotatedElementUtils.hasAnnotation(returnType.getContainingClass(), RestController.class) &&
                !returnType.getParameterType().equals(ResponseEntity.class);
    }

    @Override
    public Object beforeBodyWrite(Object body, MethodParameter returnType, MediaType selectedContentType,
                                  Class<? extends HttpMessageConverter<?>> selectedConverterType,
                                  ServerHttpRequest request, ServerHttpResponse response) {

        // If the controller has already manually wrapped the response, do nothing.
        if (body instanceof ApiResponse<?>) {
            return body;
        }

        // Wrap the successful response body in the standard ApiResponse structure.
        return ApiResponse.success(body);
    }
}






package com.fincore.ReportService.config;

import lombok.extern.slf4j.Slf4j;
import org.apache.hadoop.fs.FileSystem;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

import java.io.IOException;
import java.net.URI;
import java.net.URISyntaxException;

@Configuration
@Slf4j
public class HadoopConfig {
    @Value("${hadoop.fs.uri}")
    private String hadoopFsUri;
    @Value("${hadoop.fs.user}")
    private String hadoopUser;

    @Bean
    public FileSystem fileSystem() {

        log.info("Initializing HDFS connection to: {} as user: {}", hadoopFsUri, hadoopUser);
        org.apache.hadoop.conf.Configuration config = new org.apache.hadoop.conf.Configuration();

        // 1. Set the default FileSystem URI
        config.set("fs.defaultFS", hadoopFsUri);

        // 2. OPTIMIZATION: Disable client-side permission checking.
        // This relies on the server to check permissions, preventing local OS user mismatch errors.
//        config.set("dfs.client.use.datanode.hostname", "true");

        // 3. ROBUSTNESS: Set timeouts (default is often too high or infinite)
        config.set("ipc.client.connect.timeout", "5000"); // 5 seconds
        config.set("ipc.client.rpc-timeout.ms", "30000"); // 30 seconds

        // 4. Replication adjustment (optional, prevents warnings in single-node dev setups)
        // config.set("dfs.replication", "1");
        try {
            // Returns a FileSystem instance. The FileSystem class handles caching internally.
            // Spring will manage the lifecycle (closing it on shutdown).
            return FileSystem.get(new URI(hadoopFsUri), config, hadoopUser);

        } catch (IOException | InterruptedException | URISyntaxException e) {

            log.error("CRITICAL: Failed to connect to HDFS at {}", hadoopFsUri, e);
            throw new RuntimeException("Could not initialize Hadoop FileSystem", e);
        }
    }
}










package com.fincore.ReportService.config;

import com.fincore.ReportService.dto.TaskProgressDto;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.redis.connection.RedisConnectionFactory;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;
import org.springframework.data.redis.serializer.StringRedisSerializer;

/**
 * Configuration for the RedisTemplate used to publish TaskProgressDto.
 * Uses JSON serialization for values so the Notification Service can read them.
 */
@Configuration
public class TaskRedisConfig {

    @Bean(name = "progressRedisTemplate")
    public RedisTemplate<String, TaskProgressDto> progressRedisTemplate(RedisConnectionFactory connectionFactory) {
        RedisTemplate<String, TaskProgressDto> template = new RedisTemplate<>();
        template.setConnectionFactory(connectionFactory);

        // Keys are Strings (the topic name)
        template.setKeySerializer(new StringRedisSerializer());

        // Values are JSON (the DTO)
        Jackson2JsonRedisSerializer<TaskProgressDto> serializer = new Jackson2JsonRedisSerializer<>(TaskProgressDto.class);
        template.setValueSerializer(serializer);

        return template;
    }
}











package com.fincore.ReportService.config;

import com.fincore.commonutilities.config.CommonSecurityConfig;
import com.fincore.commonutilities.config.RedisConfig;
import com.fincore.commonutilities.jwt.JwtUtil;
import com.fincore.commonutilities.security.ContextRbacFilter;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Import;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.security.config.annotation.web.builders.HttpSecurity;
import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;
import org.springframework.security.config.http.SessionCreationPolicy;
import org.springframework.security.web.SecurityFilterChain;
import org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter;

/**
 * Common Security Configuration.
 * * Aligned with the "Distributed Gateway" architecture.
 * It uses the ContextRbacFilter from Common Utilities to enforce:
 * 1. Token Validity
 * 2. Single Session (Redis check)
 * 3. RBAC Permissions
 */
@Configuration
@EnableWebSecurity
@Import({RedisConfig.class, JwtUtil.class, CommonSecurityConfig.class}) // Import logic from JAR
public class SecurityConfig {

    @Autowired
    private StringRedisTemplate redisTemplate;

    @Autowired
    private JwtUtil jwtUtil;

    @Autowired
    private CommonSecurityConfig commonSecurityConfig; // Wire in the CORS config

    @Bean
    public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {
        http
                // 1. Disable CSRF (Stateless API)
                .csrf(csrf -> csrf.disable())

                // 2. Apply Centralized CORS Policy
                .cors(cors -> cors.configurationSource(commonSecurityConfig.corsConfigurationSource()))

                // 3. Stateless Session (No JSESSIONID)
                .sessionManagement(s -> s.sessionCreationPolicy(SessionCreationPolicy.STATELESS))

                // 4. Authorization Rules
                .authorizeHttpRequests(authz -> authz
                        // Public Endpoints
                        .requestMatchers("/actuator/**", "/auth/**", "/error").permitAll()
                        // All other endpoints require Authentication (and RBAC filter check)
                        .anyRequest().authenticated()
                )

                // 5. Add the "Distributed Gateway" Filter
                .addFilterBefore(new ContextRbacFilter(redisTemplate, jwtUtil), UsernamePasswordAuthenticationFilter.class);

        return http.build();
    }
}









package com.fincore.ReportService.controller;

import java.util.List;
import java.util.Map;

import com.fincore.ReportService.dto.ReportCreationDto;
import com.fincore.commonutilities.jwt.JwtUtil;
import lombok.extern.slf4j.Slf4j;

import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestBody;
import org.springframework.web.bind.annotation.RequestHeader;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.http.HttpHeaders;
import org.springframework.http.MediaType;
import org.springframework.web.servlet.mvc.method.annotation.StreamingResponseBody;

import com.fincore.ReportService.dto.ReportDownloadRequest;
import com.fincore.ReportService.dto.ReportStreamResponse;
import com.fincore.ReportService.dto.ReportTypeDto;
import com.fincore.ReportService.service.ReportService;



@Slf4j
@RestController
@RequestMapping("/api/reports") 
public class ReportController {

    private final ReportService reportService;
    private final JwtUtil jwtUtil; // Declare an instance field
    
    public ReportController(ReportService reportService, JwtUtil jwtUtil) {
        this.reportService = reportService;
        this.jwtUtil = jwtUtil;
    }

    @PostMapping("/types")
    public List<ReportTypeDto> getReportTypes(@RequestHeader("Authorization") String token) {
        log.info("role and user id from token  : {},  {}", jwtUtil.getUserRoleFromToken(token), jwtUtil.getUserIdFromToken(token));
        return reportService.getReportTypes(jwtUtil.getUserRoleFromToken(token));
    }

    @PostMapping("/download")
   public ResponseEntity<StreamingResponseBody> downloadReport(
           @RequestHeader("Authorization") String token,
           @RequestBody ReportDownloadRequest request) {
            log.info("REQUEST : {}",request);
       ReportStreamResponse response = reportService.downloadReportStream(
               request.getFileName(),
               request.getDate(),
               jwtUtil.getUserRoleFromToken(token),
               jwtUtil.getUserIdFromToken(token)
       );
       return ResponseEntity.ok()
               // This header tells the browser "This is a file download"
               .header(HttpHeaders.CONTENT_DISPOSITION, "attachment; filename=\"" + response.getDownloadFileName() + "\"")
               .contentType(MediaType.APPLICATION_OCTET_STREAM)
               .body(response.getStreamBody());
   }

   @PostMapping("/create-reports")
    public Map<String,String> createReports (@RequestBody ReportCreationDto requestBody) throws Exception{
           return reportService.createReports(requestBody);
    }

}









package com.fincore.ReportService.dto;
import lombok.AllArgsConstructor;
import lombok.Data;
import org.springframework.web.servlet.mvc.method.annotation.StreamingResponseBody;
@Data
@AllArgsConstructor
public class ReportStreamResponse {
   private String downloadFileName;
   private StreamingResponseBody streamBody;
}










package com.fincore.ReportService.dto;
import lombok.AllArgsConstructor;
import lombok.Data;
import org.springframework.web.servlet.mvc.method.annotation.StreamingResponseBody;
@Data
@AllArgsConstructor
public class ReportStreamResponse {
   private String downloadFileName;
   private StreamingResponseBody streamBody;
}








package com.fincore.ReportService.dto;

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;

import java.io.Serializable;

/**
 * Standard DTO for sending progress updates to the Notification Service via Redis.
 * Matches the structure required by the Notification Platform.
 */
@Data
@Builder
@NoArgsConstructor
@AllArgsConstructor
public class TaskProgressDto implements Serializable {
    private String taskId;      // Unique Job ID (e.g., "download_123_456")
    private String userId;      // The User ID to notify
    private int percentage;     // 0 to 100
    private String status;      // "PROCESSING", "COMPLETED", "FAILED"
    private String message;     // User-facing text
}









package com.fincore.ReportService.dto;

import com.fasterxml.jackson.annotation.JsonInclude;
import lombok.Getter;

import java.time.Instant;

@Getter
@JsonInclude(JsonInclude.Include.NON_NULL) // Don't include null fields in the JSON response
public class ApiResponse<T> {

    private final boolean success;
    private final String message;
    private final T data;
    private final Instant timestamp;

    private ApiResponse(boolean success, String message, T data) {
        this.success = success;
        this.message = message;
        this.data = data;
        this.timestamp = Instant.now();
    }

    public static <T> ApiResponse<T> success(T data, String message) {
        return new ApiResponse<>(true, message, data);
    }

    public static <T> ApiResponse<T> success(T data) {
        return new ApiResponse<>(true, "Operation completed successfully.", data);
    }

    public static <T> ApiResponse<T> error(String message) {
        return new ApiResponse<>(false, message, null);
    }
}












package com.fincore.ReportService.dto;

import jakarta.validation.constraints.NotBlank;
import jakarta.validation.constraints.NotNull;
import jakarta.validation.constraints.Positive;

import org.springframework.format.annotation.DateTimeFormat;

import java.time.LocalDate;

import lombok.Data;

/**
 * DTO for the request body of the "download report" endpoint.
 */
@Data
public class ReportDownloadRequest {
    /**
     * The unique name of the report.
     * - @NotBlank: Ensures the string is not null and not just whitespace.
     */
    @NotBlank(message = "file name must not be blank")
    private String fileName;

    /**
     * The date for which the report is requested.
     * - @NotNull: Ensures the date field is present.
     * - @DateTimeFormat: Ensures the string is in 'yyyy-MM-dd' format.
     */
    @NotNull(message = "date must not be null")
    @DateTimeFormat(iso = DateTimeFormat.ISO.DATE)
    private LocalDate date;


    /**
     * roleID will bne used to verify authorization for the download
     * - @NotNull: Ensures the field is present in the JSON payload.
     * - @Positive: Ensures the role ID is a number greater than zero.
     */
    @NotNull(message = "roleId must not be null")
    @Positive(message = "roleId must be a positive number")
    private int roleId;
}














package com.fincore.ReportService.dto;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

/**
 * A DTO (Data Transfer Object) to hold the structured file data
 * that will be sent back to the client in a JSON format.
 */
@Data
@NoArgsConstructor
@AllArgsConstructor
public class ReportFileDto {

    /**
     * The full name of the file, including the extension.
     * Example: "balance_compare_report_15102025.xlsx"
     */
    private String fileName;

    /**
     * The MIME type of the file. This is crucial for the frontend
     * to know how to handle the content.
     * Example: "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
     */
    private String fileType;

    /**
     * The raw content of the file, encoded as a Base64 string.
     * The frontend will decode this back into a file.
     */
    private String fileContent;
}












package com.fincore.ReportService.dto;

import java.time.LocalDate;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@NoArgsConstructor
@AllArgsConstructor
public class ReportTypeDto {

    private String reportName;

    private String fileName;

    private LocalDate selectedDate;
}







package com.fincore.ReportService.dto;

import jakarta.validation.constraints.NotNull;
import lombok.Data;

@Data
public class ReportCreationDto {

    @NotNull
    private String date;
    private String branch;
    private String cgl;
}











package com.fincore.ReportService.dto;


import jakarta.validation.constraints.NotNull;
import jakarta.validation.constraints.Positive;
import lombok.Data;

/**
 * DTO (Data Transfer Object) for the request body of the "get report types" endpoint.
 * It uses validation annotations to ensure the payload is correct.
 */
@Data
public class ReportTypesRequest {

    /**
     * The unique identifier for the user's role.
     * - @NotNull: Ensures the field is present in the JSON payload.
     * - @Positive: Ensures the role ID is a number greater than zero.
     */
    @NotNull(message = "roleId must not be null")
    @Positive(message = "roleId must be a positive number")
    private int roleId;
}















package com.fincore.ReportService.exception;

import com.fasterxml.jackson.core.JsonProcessingException;

import lombok.extern.slf4j.Slf4j;

import java.util.stream.Collectors;

import org.springframework.dao.DataIntegrityViolationException;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.http.converter.HttpMessageNotReadableException;
import org.springframework.security.access.AccessDeniedException;
import org.springframework.web.bind.MethodArgumentNotValidException;
import org.springframework.web.bind.annotation.ControllerAdvice;
import org.springframework.web.bind.annotation.ExceptionHandler;
import org.springframework.web.bind.annotation.ResponseStatus;
import org.springframework.web.context.request.WebRequest;

import com.fincore.ReportService.dto.ApiResponse;

import jakarta.validation.ConstraintViolationException;

@ControllerAdvice
@Slf4j
public class GlobalExceptionHandler {

    @ExceptionHandler(ResourceNotFoundException.class)
    public ResponseEntity<ApiResponse<Object>> handleResourceNotFoundException(ResourceNotFoundException ex, WebRequest request) {
        log.error("Report not found: {}", ex.getMessage());
        return new ResponseEntity<>(ApiResponse.error(ex.getMessage()), HttpStatus.NOT_FOUND);
    }

    @ExceptionHandler({JsonProcessingException.class, HttpMessageNotReadableException.class})
    public ResponseEntity<ApiResponse<Object>> handleJsonProcessingException(Exception ex, WebRequest request) {
        log.error("Error processing JSON payload: {}", ex.getMessage());
        return new ResponseEntity<>(ApiResponse.error("Invalid request payload format. Please check the JSON structure and data types."), HttpStatus.BAD_REQUEST);
    }

    @ExceptionHandler(DataIntegrityViolationException.class)
    public ResponseEntity<ApiResponse<Object>> handleDataIntegrityViolationException(DataIntegrityViolationException ex, WebRequest request) {
        log.error("Data integrity violation: {}", ex.getMessage());
        // Check for common unique constraint violation message
        if (ex.getMostSpecificCause().getMessage().contains("already exists")) {
            return new ResponseEntity<>(ApiResponse.error("A resource with the provided identifier already exists."), HttpStatus.CONFLICT);
        }
        return new ResponseEntity<>(ApiResponse.error("Database constraint violation. A required field may be missing or a value is invalid."), HttpStatus.CONFLICT);
    }

    @ExceptionHandler({IllegalArgumentException.class, IllegalStateException.class})
    public ResponseEntity<ApiResponse<Object>> handleArgumentAndStateExceptions(RuntimeException ex, WebRequest request) {
        log.error("Illegal argument or state: {}", ex.getMessage());
        return new ResponseEntity<>(ApiResponse.error(ex.getMessage()), HttpStatus.BAD_REQUEST);
    }

    @ExceptionHandler(Exception.class)
    public ResponseEntity<ApiResponse<Object>> handleGlobalException(Exception ex, WebRequest request) {
        log.error("An unexpected error occurred: {}", ex.getMessage(), ex);
        return new ResponseEntity<>(ApiResponse.error("An internal server error occurred."), HttpStatus.INTERNAL_SERVER_ERROR);
    }


    /**
     * Handles exceptions thrown when @Valid validation fails on a request body.
     * Returns a 400 Bad Request with a list of validation errors.
     */
    @ExceptionHandler(MethodArgumentNotValidException.class)
    @ResponseStatus(HttpStatus.BAD_REQUEST)
    public ResponseEntity<ApiResponse<Object>> handleValidationExceptions(MethodArgumentNotValidException ex) {
        // Collect all validation error messages into a single string.
        String errors = ex.getBindingResult().getFieldErrors().stream()
                .map(error -> error.getField() + ": " + error.getDefaultMessage())
                .collect(Collectors.joining(", "));
        
        log.warn("Validation failed for incoming request: {}", errors);
         return new ResponseEntity<>(ApiResponse.error("Validation Failed: "+errors), HttpStatus.BAD_REQUEST);
    }

    /**
     * Handles exceptions thrown by the Jakarta Validator, for example,
     * when we manually trigger validation in our strategies.
     */
    @ExceptionHandler(ConstraintViolationException.class)
    @ResponseStatus(HttpStatus.BAD_REQUEST)
    public ResponseEntity<ApiResponse<Object>> handleConstraintViolationException(ConstraintViolationException ex) {
        String errors = ex.getConstraintViolations().stream()
                .map(cv -> cv.getPropertyPath() + ": " + cv.getMessage())
                .collect(Collectors.joining(", "));
                
        log.warn("Constraint violation during processing: {}", errors);
        return new ResponseEntity<>(ApiResponse.error("Validation Failed: "+errors), HttpStatus.BAD_REQUEST);
    }

    @ExceptionHandler(AccessDeniedException.class)
    public ResponseEntity<ApiResponse<Object>> handleAccessDeniedException(AccessDeniedException ex, WebRequest request) {
        log.error("Access Denied: {}", ex.getMessage());
        return new ResponseEntity<>(ApiResponse.error("Report Not Found or You are not authorized to perform this action."), HttpStatus.NOT_FOUND);
    }
    
}














package com.fincore.ReportService.exception;

import org.springframework.http.HttpStatus;
import org.springframework.web.bind.annotation.ResponseStatus;

@ResponseStatus(HttpStatus.NOT_FOUND)
public class ResourceNotFoundException extends RuntimeException {
    public ResourceNotFoundException(String message) {
        super(message);
    }
}














package com.fincore.ReportService.model;

import jakarta.persistence.Column;
import jakarta.persistence.Entity;
import jakarta.persistence.GeneratedValue;
import jakarta.persistence.GenerationType;
import jakarta.persistence.Id;
import jakarta.persistence.Table;
import lombok.Getter;
import lombok.Setter;

@Entity
@Table(name = "APP_CONFIG")
@Getter
@Setter
public class AppConfig {

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private int id;

    @Column(name = "CONFIG_KEY", nullable = false, unique = true)
    private String configKey;

    @Column(name = "CONFIG_VALUE", nullable = false)
    private String configValue;

    @Column(name = "DESCRIPTION")
    private String description;

}








package com.fincore.ReportService.model;

import jakarta.persistence.Column;
import jakarta.persistence.Entity;
import jakarta.persistence.Id;
import jakarta.persistence.Table;
import lombok.Getter;
import lombok.Setter;
import org.springframework.context.annotation.Bean;
import org.springframework.stereotype.Component;

@Entity
@Table(name = "JASPER_REPORTS")
@Getter
@Setter
public class JasperReports {

    @Id
    private String type;

    @Column(name = "FILENAME", nullable = false)
    private String fileName;

    @Column(name = "PARAMS")
    private String params;
 }








package com.fincore.ReportService.model;

import jakarta.persistence.*;
import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;
import org.hibernate.annotations.CreationTimestamp; // Import this
import org.springframework.data.jpa.domain.support.AuditingEntityListener;

import java.io.Serializable;
import java.time.Instant; // This is the correct type
import java.util.Objects;
import java.util.UUID;

/**
 * Represents an event in the outbox system, intended for notification purposes.
 * UPDATED: Added @CreationTimestamp for automatic timestamping.
 */
@Entity
@Table(name = "Notifications")
@Builder
@Data
@NoArgsConstructor
@AllArgsConstructor
@EntityListeners(AuditingEntityListener.class)
public class Notifications implements Serializable {

    // Unique primary key for the outbox event.
    // Using UUID strategy is correct for Oracle's SYS_GUID() or RAW(16)
    @Id
    @GeneratedValue(strategy = GenerationType.UUID)
    @Column(name = "EVENT_ID", updatable = false, nullable = false)
    private UUID eventId;

    // The ID of the user who should receive this notification (for 1-to-1).
    @Column(name = "USER_ID", length = 255)
    private String userId;

    // The human-readable message to be displayed.
    @Column(name = "MESSAGE", length = 1024, nullable = false)
    private String message;

    // The relative URL the user should be taken to when clicking the notification.
    @Column(name = "LINK_URL", length = 1024)
    private String linkUrl;

    // The microservice that generated this event.
    @Column(name = "EVENT_SOURCE", length = 100)
    private String eventSource;

    // The primary key of the business object (e.g., the CommonReq ID).
    @Column(name = "AGGREGATE_ID", length = 255)
    private String aggregateId;

    // The timestamp when the event was created.
    @CreationTimestamp
    @Column(name = "EVENT_TIMESTAMP", nullable = false, updatable = false)
    private Instant eventTimestamp;

    // For 1-to-Many notifications. If USER_ID is null, this role is used.
    @Column(name = "TARGET_ROLE", length = 100)
    private String targetRole;


    @Override
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || getClass() != o.getClass()) return false;
        Notifications that = (Notifications) o;
        return Objects.equals(eventId, that.eventId);
    }

    @Override
    public int hashCode() {
        return Objects.hash(eventId);
    }


    @Override
    public String toString() {
        return "NotificationTable{" +
                "eventId='" + eventId + '\'' +
                ", userId='" + userId + '\'' +
                ", targetRole='" + targetRole + '\'' +
                ", eventSource='" + eventSource + '\'' +
                ", aggregateId='" + aggregateId + '\'' +
                ", eventTimestamp=" + eventTimestamp +
                '}';
    }
}












package com.fincore.ReportService.model;


import jakarta.persistence.*;
import lombok.Data;
import lombok.ToString;

import org.hibernate.annotations.CreationTimestamp;

import java.time.Instant;
import java.util.Set;

import lombok.Getter;
import lombok.Setter;

@Entity
@Table(name = "REPORT_TYPES")
@Getter
@Setter
public class ReportType {

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private int id;

    @Column(name = "REPORT_NAME", nullable = false, unique = true)
    private String reportName;

    @CreationTimestamp
    @Column(name = "CREATED_AT", updatable = false)
    private Instant createdAt;

    @Column(name = "FILE_NAME")    
    private String fileName;

    @ManyToMany(fetch = FetchType.LAZY)
    @JoinTable(
            name = "REPORT_ROLE_MAPPING",
            joinColumns = @JoinColumn(name = "report_type_id"),
            inverseJoinColumns = @JoinColumn(name = "role_id")
    )
    private Set<Role> roles;
}














package com.fincore.ReportService.model;

import java.util.Set;

import jakarta.persistence.Column;
import jakarta.persistence.Entity;
import jakarta.persistence.Id;
import jakarta.persistence.ManyToMany;
import jakarta.persistence.Table;
import lombok.Data;

@Entity
@Data
@Table(name = "ROLES")
public class Role {
    
    @Id
    @Column(name = "ROLE_ID" )
    private Integer roleId;

    @Column(name = "ROLE_NAME")
    private String roleName;

    @Column(name = "DESCRIPTION")
    private String description;

    @Column(name = "ROLE_STATUS")
    private String role_status;

    @ManyToMany(mappedBy = "roles")
    private Set<ReportType> reportTypes;
}















package com.fincore.ReportService.repository;

import java.util.Optional;

import org.springframework.data.jpa.repository.JpaRepository;

import com.fincore.ReportService.model.AppConfig;

public interface AppConfigRepository extends JpaRepository<AppConfig, Integer> {

    Optional<AppConfig> findByConfigKey(String configKey);

}










package com.fincore.ReportService.repository;

import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.stereotype.Repository;

import com.fincore.ReportService.model.Notifications;

import java.util.UUID;

/**
 * 
 */
@Repository
public interface NotificationRepository extends JpaRepository<Notifications, UUID>{

}










package com.fincore.ReportService.repository;

import java.util.List;

import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import com.fincore.ReportService.model.ReportType;

@Repository
public interface ReportTypeRepository extends JpaRepository<ReportType, Integer> {

    /**
     * Finds all report types and orders them by their REPORT_NAME for a better user experience.
     * @return A list of ReportType entities.
     */
    // This method is still useful for admins or internal tools.
    List<ReportType> findAllByOrderByReportNameAsc();

    /**
     * Finds all report types accessible by a specific role ID.
     * This query joins ReportType with its roles and filters by the role's primary key.
     * The result is ordered by the reportName to ensure a consistent and user-friendly order in the dropdown.
     *
     * @param roleId The primary key ID of the role.
     * @return A list of accessible ReportType entities.
     */
    @Query("SELECT rt FROM ReportType rt JOIN rt.roles r WHERE r.roleId = :roleId ORDER BY rt.reportName ASC")
    List<ReportType> findByRoleId(@Param("roleId") int roleId);

    // Optional<ReportType> findByFileName(String fileName);
    
    boolean existsByFileNameAndRoles_roleId(String fileName, int roleId); 

}






package com.fincore.ReportService.repository;

import com.fincore.ReportService.model.JasperReports;
import org.springframework.data.domain.Example;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.stereotype.Repository;

import java.util.List;

@Repository
public interface JasperReportTypeRepository extends JpaRepository<JasperReports,String> {
    List<JasperReports> findAll();
}

















package com.fincore.ReportService.service;


import com.fincore.ReportService.model.Notifications;
import com.fincore.ReportService.repository.NotificationRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Propagation;
import org.springframework.transaction.annotation.Transactional;

/**
 * A service to create and save Notification events to the outbox table.
 * This is designed to be called from within a parent @Transactional method
 * in RequestServiceImpl to ensure atomic operations.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class NotificationWriterService {

    private final NotificationRepository notificationRepository;

    /**
     * Creates and saves a notification outbox event.
     * This method joins the existing transaction from the calling service.
     *
     * @param userId       The specific user to notify (for 1-to-1). Null if using targetRole.
     * @param targetRole   The role to notify (for 1-to-many). Null if using userId.
     * @param message      The human-readable message.
     * @param linkUrl      The frontend link for the notification.
     * @param aggregateId  The ID of the business object (e.g., the CommonReq ID).
     * @param eventSource  The name of this service.
     */
    @Transactional(propagation = Propagation.REQUIRES_NEW) // Ensures this is only called from within an existing transaction
    public void createNotification(String userId, String targetRole, String message, String linkUrl, String aggregateId, String eventSource) {

        if (userId == null && targetRole == null) {
            log.warn("Skipping notification creation: Both userId and targetRole are null. AggregateID: {}", aggregateId);
            // In a real scenario, you might want to throw an exception here
            // if one of them is strictly required, to roll back the parent transaction.
            return;
        }

        if (message == null || message.isBlank()) {
            log.warn("Skipping notification creation: Message is null or blank. AggregateID: {}", aggregateId);
            // Throwing an exception ensures the parent transaction rolls back.
            throw new IllegalArgumentException("Notification message cannot be null or blank.");
        }

        Notifications notification = Notifications.builder()
                .userId(userId)
                .targetRole(targetRole)
                .message(message)
                .linkUrl(linkUrl)
                .aggregateId(aggregateId)
                .eventSource(eventSource)
                .build();

        // The EVENT_ID (UUID) and EVENT_TIMESTAMP (CreationTimestamp)
        // will be set automatically by the NotificationTable entity.

        notificationRepository.save(notification);

        if (userId != null) {
            log.info("Saved 1-to-1 notification event for user: {} (AggregateID: {})", userId, aggregateId);
        } else {
            log.info("Saved 1-to-many notification event for role: {} (AggregateID: {})", targetRole, aggregateId);
        }
    }
}










package com.fincore.ReportService.service;

import java.time.LocalDate;
import java.util.List;
import java.util.Map;

import com.fincore.ReportService.dto.ReportCreationDto;
import com.fincore.ReportService.dto.ReportStreamResponse;
import com.fincore.ReportService.dto.ReportTypeDto;

public interface ReportService {

    /**
     * Retrieves all report types accessible by a specific user role ID.
     *
     * @param roleId The ID of the user's role.
     * @return A list of {@link ReportTypeDto}.
     */
    List<ReportTypeDto> getReportTypes(int roleId);
    
    /**
    * returns a wrapper containing the filename and the stream logic
    */
   ReportStreamResponse downloadReportStream(String fileName, LocalDate date, int userRoleId, String userId);

    /**
     * returns report name and jasper file name
     */
    Map<String,String> createReports(ReportCreationDto parameters) throws Exception;
 }


















package com.fincore.ReportService.service;

import com.fincore.ReportService.dto.ReportCreationDto;
import com.fincore.ReportService.dto.ReportStreamResponse;
import com.fincore.ReportService.dto.ReportTypeDto;
import com.fincore.ReportService.exception.ResourceNotFoundException;
import com.fincore.ReportService.model.AppConfig;
import com.fincore.ReportService.model.JasperReports;
import com.fincore.ReportService.model.ReportType;
import com.fincore.ReportService.repository.AppConfigRepository;
import com.fincore.ReportService.repository.JasperReportTypeRepository;
import com.fincore.ReportService.repository.ReportTypeRepository;
import lombok.extern.slf4j.Slf4j;
import net.sf.jasperreports.engine.JRException;
import net.sf.jasperreports.engine.JasperExportManager;
import net.sf.jasperreports.engine.JasperFillManager;
import net.sf.jasperreports.engine.JasperPrint;
import net.sf.jasperreports.engine.export.JRCsvExporter;
import net.sf.jasperreports.engine.export.ooxml.JRXlsxExporter;
import net.sf.jasperreports.export.SimpleCsvExporterConfiguration;
import net.sf.jasperreports.export.SimpleExporterInput;
import net.sf.jasperreports.export.SimpleOutputStreamExporterOutput;
import net.sf.jasperreports.export.SimpleWriterExporterOutput;
import org.apache.hadoop.fs.*;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.core.io.ClassPathResource;
import org.springframework.security.access.AccessDeniedException;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;
import org.springframework.util.StreamUtils;
import org.springframework.web.servlet.mvc.method.annotation.StreamingResponseBody;

import javax.sql.DataSource;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.io.InputStream;
import java.nio.file.Paths;
import java.sql.Connection;
import java.time.LocalDate;
import java.time.format.DateTimeFormatter;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import java.util.stream.Collectors;
import java.util.zip.ZipEntry;
import java.util.zip.ZipOutputStream;

/**
 * Service implementation for handling business logic related to GLIF reports.
 */
@Service
@Slf4j
public class ReportServiceImpl implements ReportService {

    @Autowired
    private DataSource dataSource;

    @Value("${directory.jasperFileDir:/jasper}")
    private String jasperFileDir;

    private final ReportTypeRepository reportTypeRepository;
    private final JasperReportTypeRepository jasperReportTypeRepository;
    private final String reportsBasePath;
    private final AppConfigRepository appConfigRepository;
    private final NotificationWriterService notificationWriterService;
    private final FileSystem hdfsFileSystem;
    private final String REPORTS_START_DATE_KEY = "REPORTS_START_DATE";

    public ReportServiceImpl(ReportTypeRepository reportTypeRepository,JasperReportTypeRepository jasperReportTypeRepository,
                             @Value("${glif.reports.base-path}") String basePath, AppConfigRepository appConfigRepository,
                             NotificationWriterService notificationWriterService, FileSystem hdfsFileSystem) {
        this.reportTypeRepository = reportTypeRepository;
        this.jasperReportTypeRepository=jasperReportTypeRepository;
        this.reportsBasePath = basePath;
        this.appConfigRepository = appConfigRepository;
        this.notificationWriterService = notificationWriterService;
        this.hdfsFileSystem = hdfsFileSystem;
    }

    /**
     * Retrieves a list of report types that are explicitly mapped to the given
     * roleId AND start date from app_config table.
     *
     * @param roleId The ID of the user's role.
     * @return A list of DTOs representing the available reports and start date.
     */
    @Override
    public List<ReportTypeDto> getReportTypes(int roleId) {
        if (roleId <= 0) {
            throw new IllegalArgumentException("Payload structure is not correct.");
        }
        log.info("Fetching GLIF report types for roleId: {}", roleId);

        // Fetch the date from appConfig to validate the start date of date-picker
        LocalDate startDate = getStartDateFromAppConfig();

        return reportTypeRepository.findByRoleId(roleId).stream()
                .map(reportType -> new ReportTypeDto(reportType.getReportName(), reportType.getFileName(), startDate))
                .collect(Collectors.toList());
    }

    @Transactional
    @Override
    public ReportStreamResponse downloadReportStream(String fileName, LocalDate date, int userRoleId, String userId) {
        // 1. Authorization Check
        ReportType reportType = reportTypeRepository.findByFileNameAndRoles_roleId(fileName, userRoleId)
                .orElseThrow(() -> {
                    log.warn("Access Denied: User {} -> Report {}", userId, fileName);
                    sendNotification(userId, "Access Denied for report: " + fileName, "/glif-reports", fileName + "_" + date);
                    return new AccessDeniedException("Access Denied for report: " + fileName);
                });

        log.info("Fetched report from db : {}", reportType);
        // This is the human-readable name (e.g., "Daily Balance Sheet")
        String reportDisplayName = reportType.getReportName();


        // 2. Prepare Paths with the CORRECT format "dd-MM-yyyy"
        String formattedDate = date.format(DateTimeFormatter.ISO_LOCAL_DATE);
        Path searchDirectory = new Path(reportsBasePath, formattedDate);
        String fileNamePrefix = fileName + "_" + date.format(DateTimeFormatter.ofPattern("ddMMyyyy"));
        log.info("Searching HDFS directory {} for files with prefix '{}'...", searchDirectory, fileNamePrefix);

        // 3. Define the Streaming Logic
        StreamingResponseBody streamingBody = outputStream -> {
            try (ZipOutputStream zipOut = new ZipOutputStream(outputStream)) {
                if (!hdfsFileSystem.exists(searchDirectory)) {
                    log.info("Directory not found in HDFS: {}", searchDirectory);
                    // Throw immediately so a proper HTTP 404 is sent to the client
                    throw new ResourceNotFoundException("Reports directory not found: " + searchDirectory);
                }

                FileStatus[] fileStatuses = hdfsFileSystem.listStatus(searchDirectory);
                boolean fileFound = false;

                for (FileStatus status : fileStatuses) {
                    if (!status.isFile()) continue;
                    String actualFileName = status.getPath().getName();

                    if (actualFileName.startsWith(fileNamePrefix)) {
                        fileFound = true;
                        ZipEntry zipEntry = new ZipEntry(actualFileName);
                        zipOut.putNextEntry(zipEntry);

                        try (FSDataInputStream hdfsStream = hdfsFileSystem.open(status.getPath())) {
                            StreamUtils.copy(hdfsStream, zipOut);
                        } finally {
                            zipOut.closeEntry();
                        }
                        log.info("Streamed file {} into zip response.", actualFileName);
                    }
                }

                if (!fileFound) {
                    log.info("No report files found matching prefix: " + fileNamePrefix);
                    // Throw immediately so a proper HTTP 404 is sent to the client
                    throw new ResourceNotFoundException("No report files found matching prefix: " + fileNamePrefix);
                }

                // Notification is only sent AFTER all files are confirmed found and streamed
                String successMsg = String.format("%s downloaded successfully.", reportDisplayName);
                sendNotification(userId, successMsg, "/glif-reports", fileName + "_" + date);
//                sendNotification(userId, "Report(s) downloaded successfully.", "/glif-reports", fileName + "_" + date);

            } catch (ResourceNotFoundException e) {
                // If a resource error happens before streaming starts, it's caught here
                log.error("Resource not found error: {}", e.getMessage());
                sendNotification(userId, reportDisplayName+" is not available.", "/glif-reports", fileName + "_" + date);
                // Note: The controller must catch this exception to return a proper 404
            } catch (IOException e) {
                // If an I/O error happens DURING streaming, the client will see a failed download
                // Includes the internet/network-down , HDFS down and NameNode not reachable cases
                log.error("Streaming I/O error for user {}: {}", userId, e.getMessage(), e);
                sendNotification(userId, "Download failed due to a streaming or internet issue. Please check your connection and try again.", "/glif-reports", fileName + "_" + date);
            }
        };

        String downloadName = fileName + "_" + formattedDate + ".zip";
        return new ReportStreamResponse(downloadName, streamingBody);
    }

    @Override
    public Map<String, String> createReports(ReportCreationDto parameters) throws Exception {

        // Map to store report generation status
        Map<String, String> reportStat = new HashMap<>();

        // Convert input date (dd/MM/yyyy â†’ yyyy-MM-dd)
        LocalDate reportDate = LocalDate.parse(
                parameters.getDate(),
                DateTimeFormatter.ofPattern("dd/MM/yyyy")
        );

        String formattedDate = reportDate.format(DateTimeFormatter.ISO_LOCAL_DATE);
        String datePrefix = reportDate.format(DateTimeFormatter.ofPattern("ddMMyyyy"));

        // Create HDFS directory path for reports
        Path reportDir = new Path(reportsBasePath, formattedDate);

        // Create directory if not exists
        if (!hdfsFileSystem.exists(reportDir)) {
            hdfsFileSystem.mkdirs(reportDir);
            log.info("Created HDFS directory: {}", reportDir);
        }
        log.info("Directory found :  {}", reportDir);

        // Fetch all report definitions
        List<JasperReports> reportsDetails = jasperReportTypeRepository.findAll();
        log.info("Fetched {} reports", reportsDetails.size());

        // Load logo (optional)
        String logoPath = null;
        try {
            logoPath = new ClassPathResource("images/logo.png").getFile().getAbsolutePath();
        } catch (Exception e) {
            log.warn("Logo not found, continuing without logo");
        }

        // Reuse single DB connection for all reports (IMPORTANT OPTIMIZATION)
        try (Connection connection = dataSource.getConnection()) {

            // Loop through each report definition
            for (JasperReports report : reportsDetails) {

                String reportName = report.getType();
                String jasperFileName = report.getFileName();
                java.nio.file.Path jasperPath = Paths.get(jasperFileDir,jasperFileName);
                
                log.info("Generating report: {}", reportName);
                StringBuilder status = new StringBuilder();

                try (InputStream jasperStream = new FileInputStream(jasperPath.toString())) {

                    // Jasper parameters
                    Map<String, Object> reportParams = new HashMap<>();
                    reportParams.put("imagePath", logoPath);
                    reportParams.put("date", parameters.getDate());

                    // Fill Jasper report
                    JasperPrint jasperPrint = JasperFillManager.fillReport(
                            jasperStream,
                            reportParams,
                            connection
                    );

                    // ---------- PDF EXPORT ----------
                    Path pdfPath = new Path(reportDir, reportName + "_" + datePrefix + ".pdf");
                    try (FSDataOutputStream pdfOut = hdfsFileSystem.create(pdfPath, true)) {
                        JasperExportManager.exportReportToPdfStream(jasperPrint, pdfOut);
                        status.append("PDF generated");
                    }catch (JRException e) {
                        status.append("Error Occurred while generating PDF file.");
                    }


                    // ---------- EXCEL EXPORT ----------
                    Path xlsxPath = new Path(reportDir, reportName + "_" + datePrefix + ".xlsx");
                    try (FSDataOutputStream xlsxOut = hdfsFileSystem.create(xlsxPath, true)) {

                        JRXlsxExporter xlsxExporter = new JRXlsxExporter();
                        xlsxExporter.setExporterInput(new SimpleExporterInput(jasperPrint));
                        xlsxExporter.setExporterOutput(
                                new SimpleOutputStreamExporterOutput(xlsxOut)
                        );
                        xlsxExporter.exportReport();
                        status.append(", Excel generated");
                    }catch (JRException e) {
                        status.append(", Error Occurred while generating Excel file.");
                    }

                    // ---------- Pipe seperated,PSV EXPORT ----------
                    Path psvPath = new Path(reportDir, reportName + "_" + datePrefix + ".psv");
                    try (FSDataOutputStream psvOut = hdfsFileSystem.create(psvPath, true)) {

                        JRCsvExporter csvExporter = new JRCsvExporter();
                        csvExporter.setExporterInput(new SimpleExporterInput(jasperPrint));
                        csvExporter.setExporterOutput(
                                new SimpleWriterExporterOutput(psvOut)
                        );

                        SimpleCsvExporterConfiguration csvConfig =
                                new SimpleCsvExporterConfiguration();
                        csvConfig.setFieldDelimiter("|");

                        csvExporter.setConfiguration(csvConfig);
                        csvExporter.exportReport();
                        status.append(", PSV generated");
                    }catch (JRException e) {
                        status.append(", Error Occurred while generating PSV file.");
                    }

                    reportStat.put(reportName, status.toString());

                } catch (FileNotFoundException e) {
                    log.warn("Jasper file not found for {}", reportName);
                    reportStat.put(reportName, "Jasper file not found");
                }catch (JRException e) {
                    log.warn("Error Occurred while generating reports for : {}", reportName);
                    reportStat.put(reportName, "Error Occurred while generating reports");
                }
            }
            return reportStat;
        }
    }

    // =============================== Helper Functions ==================================

    private void sendNotification(String userId, String message, String url, String aggregateId) {
        try {
            notificationWriterService.createNotification(userId, null, message, url, aggregateId, "ReportService");
        } catch (Exception e) {
            log.warn("Failed to send notification to user {}: {}", userId, e.getMessage());
        }
    }

    private LocalDate getStartDateFromAppConfig() {
        return appConfigRepository.findByConfigKey(REPORTS_START_DATE_KEY)
                .map(AppConfig::getConfigValue)
                .map(LocalDate::parse)
                .orElseThrow(() -> new ResourceNotFoundException("Required App Configurations are missing for key: " + REPORTS_START_DATE_KEY));
    }
}























package com.fincore.ReportService;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@SpringBootApplication
public class ReportServiceApplication {

	public static void main(String[] args) {
		SpringApplication.run(ReportServiceApplication.class, args);
	}

}










package com.fincore.ReportService;

import org.springframework.boot.builder.SpringApplicationBuilder;
import org.springframework.boot.web.servlet.support.SpringBootServletInitializer;

public class ServletInitializer extends SpringBootServletInitializer {

	@Override
	protected SpringApplicationBuilder configure(SpringApplicationBuilder application) {
		return application.sources(ReportServiceApplication.class);
	}

}





package com.fincore.ReportService.util;

import jakarta.annotation.PostConstruct;
import lombok.extern.slf4j.Slf4j;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Component;
import java.io.IOException;
import java.net.URI;

@Component
@Slf4j
public class HadoopConnectivityTester {

    @Value("${hadoop.fs.uri}")
    private String hdfsUri;

    @Value("${hadoop.fs.user}")
    private String hdfsUser;

    @PostConstruct
    public void testHdfsConnection() {
        log.info("Attempting to connect to HDFS at: " + hdfsUri + " as user: " + hdfsUser);
        System.setProperty("HADOOP_USER_NAME", hdfsUser);

        Configuration conf = new Configuration();

        FileSystem fs = null;
        try {
            // Get the FileSystem instance using the URI
            fs = FileSystem.get(URI.create(hdfsUri), conf);

            // Perform a lightweight operation, like checking if the root directory exists
            Path rootPath = new Path("/");
            if (fs.exists(rootPath)) {
                log.info("SUCCESS: Successfully connected to HDFS and accessed the root directory.");
                log.info("HDFS default block size: " + fs.getDefaultBlockSize(rootPath));
            } else {
                log.info("FAILURE: Connected to HDFS, but root path does not exist (unexpected error).");
            }

        } catch (IOException e) {
            log.info("ERROR: Failed to connect to HDFS server or perform file system operation.");
            log.info("Check firewall rules, network connectivity, and NameNode status.");
            log.error("error : "+e.getMessage() + " :  " + e);
            // Depending on requirements, you might throw a runtime exception here
            // to stop the application from starting if HDFS access is mandatory.
        } finally {
            if (fs != null) {
                try {
                    fs.close();
                } catch (IOException e) {
                    log.info("Warning: Failed to close FileSystem instance.");
                }
            }
        }
    }
}









spring.application.name=ReportService

# LOGIN SERVICE KEY USED BY common-entities
jwt.secret=bWV0aGlvbnlsdGhyZW9ueWx0aHJlb255bGdsdXRhbWlueWxhbGFueWw=

spring.profiles.active=dev

# ===================================================================
# SERVER CONFIGURATION
# ===================================================================
server.port=9005



spring.datasource.driver-class-name=oracle.jdbc.OracleDriver
# ===================================================================
# CUSTOM APPLICATION PROPERTIES
# ===================================================================
# IMPORTANT: This is the base directory path where reports are stored. [absolute path]
# The application will look for date-named folders (e.g., "2025-10-15") inside this path.
#glif.reports.base-path=E:/media/Fincore/glif-reports


spring.mvc.async.request-timeout=3600000


notification.progress.topic=notifications:progress







# ===================================================================
# SPRING DATASOURCE (ORACLE)
# ===================================================================
spring.datasource.url=jdbc:oracle:thin:@10.177.103.192:1523/fincorepdb1
spring.datasource.username=fincore
spring.datasource.password=Password#1234


# ========================== actuator =============================
management.endpoints.web.exposure.include=*
# Always show full details on the health endpoint (e.g., database connection status)
management.endpoint.health.show-details=always

# Add some custom info to the /info endpoint
info.app.name=ReportService
info.app.description=Service to manage and retrieve different reports
info.app.version=1.0.0

# ===================================================================
# JPA / HIBERNATE CONFIGURATION
# ===================================================================
spring.jpa.database-platform=org.hibernate.dialect.OracleDialect
spring.jpa.hibernate.ddl-auto=validate
spring.jpa.show-sql=false
spring.jpa.properties.hibernate.format_sql=false
logging.level.org.hibernate.SQL=OFF
logging.level.org.hibernate.orm.jdbc.bind=OFF



# ===================================================================
# HADOOP / HDFS CONFIGURATION
# ===================================================================
hadoop.fs.uri=hdfs://10.177.103.199:8022
hadoop.fs.user=root
glif.reports.base-path=/reports


# --- Redis Configuration ---
spring.data.redis.host=10.0.17.242
spring.data.redis.port=6379
spring.cache.type=redis










docker file :
# Use Red Hat UBI with OpenJDK 17 (if accessible internally)
FROM alpine/java:22-jdk

# Set working directory inside container
#WORKDIR /app

ARG JAR_FILE=target/*.jar
# Set environment variable (optional)
ENV SPRING_PROFILES_ACTIVE=dev
ENV SERVER_PORT=9005

# Copy JAR file into the container
COPY ${JAR_FILE} app.jar

EXPOSE 9005

# Run your Spring Boot app
CMD ["java", "-jar", "app.jar"]












