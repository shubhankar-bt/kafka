2026-01-29 18:26:26.045 INFO  [http-nio-9005-exec-5] c.f.R.c.ReportController: Received request to fetch all available report types formodule: BRANCH_WISE for role: 51 
2026-01-29 18:26:31.397 INFO  [http-nio-9005-exec-7] c.f.R.c.ReportController: Received request to download report from HDFS for this criteria: ReportDownloadRequest(fileName=intr_report, date=2026-01-07, branchCode=31776) 
2026-01-29 18:26:31.435 INFO  [http-nio-9005-exec-7] c.f.R.s.ReportServiceImpl: Fetched report from db : INTR Report (Core Interbranch Report) 
2026-01-29 18:26:31.436 INFO  [http-nio-9005-exec-7] c.f.R.s.ReportServiceImpl: branch code :  31776 
2026-01-29 18:26:31.437 INFO  [http-nio-9005-exec-7] c.f.R.s.ReportServiceImpl: Searching HDFS directory /branch_reports/31776/2026-01-07 for branch wise reports with prefix 'intr_report_07012026'... 
2026-01-29 18:26:52.676 WARN  [task-2] o.a.h.h.c.i.BlockReaderFactory: I/O error constructing remote block reader. 
java.net.ConnectException: Connection timed out: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:1060)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:600)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3033)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:829)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:754)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:381)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:715)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:645)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:845)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:918)
	at java.base/java.io.DataInputStream.read(DataInputStream.java:109)
	at com.fincore.ReportService.service.ReportServiceImpl.lambda$downloadReportStream$3(ReportServiceImpl.java:222)
	at org.springframework.web.servlet.mvc.method.annotation.StreamingResponseBodyReturnValueHandler$StreamingResponseBodyTask.call(StreamingResponseBodyReturnValueHandler.java:110)
	at org.springframework.web.servlet.mvc.method.annotation.StreamingResponseBodyReturnValueHandler$StreamingResponseBodyTask.call(StreamingResponseBodyReturnValueHandler.java:97)
	at org.springframework.web.context.request.async.WebAsyncManager.lambda$startCallableProcessing$4(WebAsyncManager.java:348)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1570)
2026-01-29 18:26:52.677 WARN  [task-2] o.a.h.h.DFSInputStream: Failed to connect to /10.177.103.192:50012 for file /branch_reports/31776/2026-01-07/intr_report_07012026.csv for block BP-349774995-10.177.103.199-1767614994998:blk_1073742694_1881, add to deadNodes and continue.  
java.net.ConnectException: Connection timed out: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:1060)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:600)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3033)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:829)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:754)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:381)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:715)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:645)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:845)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:918)
	at java.base/java.io.DataInputStream.read(DataInputStream.java:109)
	at com.fincore.ReportService.service.ReportServiceImpl.lambda$downloadReportStream$3(ReportServiceImpl.java:222)
	at org.springframework.web.servlet.mvc.method.annotation.StreamingResponseBodyReturnValueHandler$StreamingResponseBodyTask.call(StreamingResponseBodyReturnValueHandler.java:110)
	at org.springframework.web.servlet.mvc.method.annotation.StreamingResponseBodyReturnValueHandler$StreamingResponseBodyTask.call(StreamingResponseBodyReturnValueHandler.java:97)
	at org.springframework.web.context.request.async.WebAsyncManager.lambda$startCallableProcessing$4(WebAsyncManager.java:348)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1570)
2026-01-29 18:26:52.678 WARN  [task-2] o.a.h.h.DFSInputStream: No live nodes contain block BP-349774995-10.177.103.199-1767614994998:blk_1073742694_1881 after checking nodes = [DatanodeInfoWithStorage[10.177.103.192:50012,DS-cbfb2f2c-3a8b-45d6-9d98-0f8ad262e39a,DISK]], ignoredNodes = null 
2026-01-29 18:26:52.678 INFO  [task-2] o.a.h.h.DFSInputStream: Could not obtain BP-349774995-10.177.103.199-1767614994998:blk_1073742694_1881 from any node:  No live nodes contain current block Block locations: DatanodeInfoWithStorage[10.177.103.192:50012,DS-cbfb2f2c-3a8b-45d6-9d98-0f8ad262e39a,DISK] Dead nodes:  DatanodeInfoWithStorage[10.177.103.192:50012,DS-cbfb2f2c-3a8b-45d6-9d98-0f8ad262e39a,DISK]. Will get new block locations from namenode and retry... 
2026-01-29 18:26:52.678 WARN  [task-2] o.a.h.h.DFSInputStream: DFS chooseDataNode: got # 1 IOException, will wait for 1952.1341959211188 msec. 
