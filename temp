global:
  scrape_interval: 5s # Poll every 5 seconds

scrape_configs:
  - job_name: 'notification_service'
    metrics_path: '/actuator/prometheus'
    static_configs:
      # 'host.docker.internal' allows the Docker container to talk to your
      # Java app running on the Host machine (IntelliJ/Eclipse).
      # If you deploy Java inside Docker later, change this to the container name.
      - targets: ['host.docker.internal:9010'] 
        labels:
          application: 'NotificationService'





version: '3.8'

services:
  # ------------------------------------------------------------------
  # 1. DATABASE & CACHE
  # ------------------------------------------------------------------
  postgres-db:
    image: bitnami/postgresql:latest
    container_name: postgres-db
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: notification_user
      POSTGRES_PASSWORD: notification_password
      POSTGRES_DB: notification_db
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - kafka-net

  redis:
    image: bitnami/redis:latest
    container_name: redis
    ports:
      - "6379:6379"
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    networks:
      - kafka-net

  # ------------------------------------------------------------------
  # 2. KAFKA INFRASTRUCTURE
  # ------------------------------------------------------------------
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - kafka-net

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - kafka-net

  connect:
    image: confluentinc/cp-kafka-connect:latest
    container_name: connect
    ports:
      - "8083:8083"
    depends_on:
      - kafka
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka:29092"
      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_CONFIG_STORAGE_TOPIC: "connect-configs"
      CONNECT_OFFSET_STORAGE_TOPIC: "connect-offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "connect-status"
      CONNECT_REPLICATION_FACTOR: 1
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_REST_ADVERTISED_HOST_NAME: "connect"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/plugins"
    volumes:
      - ./plugins:/plugins
    networks:
      - kafka-net

  # ------------------------------------------------------------------
  # 3. MONITORING STACK
  # ------------------------------------------------------------------
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    networks:
      - kafka-net
    extra_hosts:
      - "host.docker.internal:host-gateway"

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - prometheus
    volumes:
      - grafana-data:/var/lib/grafana
    networks:
      - kafka-net

networks:
  kafka-net:
    driver: bridge

volumes:
  postgres-data:
  prometheus-data:
  grafana-data:













<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
    <scope>runtime</scope>
</dependency>

**`application.properties`**
```properties
management.endpoints.web.exposure.include=health,info,prometheus
management.endpoint.prometheus.enabled=true
management.metrics.tags.application=${spring.application.name}

**Sanity Check:**
Run your Java app and visit `http://localhost:9010/actuator/prometheus`. You must see text output.

---

### 5. Start and Verify Infrastructure

1.  **Start Docker:**
    ```bash
    docker-compose up -d
    2.  **Check Prometheus Target:**
    * Open `http://localhost:9090/targets`
    * Look for `notification_service`.
    * **Status must be UP (Green).**
    * *If it is RED:* It means Prometheus can't talk to your Java app. Check if `host.docker.internal` is working or firewall rules.

---

### 6. Setting up Grafana Dashboards

Now for the fun part: Visualizing the data.

1.  **Login:** Open `http://localhost:3000`. Login with `admin` / `admin`.
2.  **Connect Data Source:**
    * Go to **Configuration (Gear Icon) > Data Sources**.
    * Click **Add data source**.
    * Select **Prometheus**.
    * **URL:** `http://prometheus:9090` (Since they are in the same Docker network).
    * Click **Save & Test**. You should see green success message.

3.  **Import JVM Dashboard (The "Micrometer" Dashboard):**
    * Go to **Dashboards (Square Icon) > Import**.
    * You can upload JSON or use an ID. Use ID **4701** (JVM (Micrometer)).
    * Select your Prometheus data source.
    * Click **Import**.
    * **Result:** You will see graphs for Heap Memory, CPU usage, Garbage Collection, and Uptime.

4.  **Create Custom "Notification Latency" Panel:**
    * Go to **Dashboards > New Dashboard**.
    * Click **Add a new panel**.
    * **Query:** `http_server_requests_seconds_max{uri="/notifications/create-request"}`
    * This will plot the max latency of your endpoint.

You now have a professional monitoring stack running alongside your application.















