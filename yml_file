services:
  # ---------------------
  # 2. Kafka (Official Apache) - Configured for KRaft
  # ---------------------
  kafka:
    image: apache/kafka:latest
    container_name: kafka
    # Depends_on zookeeper is removed
    ports:
      - "9092:9092"
    environment:
      # --- KRaft-specific configurations ---
      KAFKA_PROCESS_ROLES: "broker,controller"
      # Node ID must be unique. Here we use 1.
      KAFKA_NODE_ID: "1"
      # Quorum voters format: [node_id]@[hostname]:[port]
      # Using the internal service name 'kafka' and an internal port 9093 for the controller listener
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      # ADD THIS LINE: Explicitly define the controller listener name
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      # --- Listener configurations ---
      # Define all listeners
      KAFKA_LISTENERS: "PLAINTEXT://:9092,CONTROLLER://0.0.0.0:9093"
      # Define advertised listeners for external access
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092"
      # Map security protocols
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
      # --- General Kafka configurations ---
      KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_CFG_OFFSET_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_CFG_LOG_RETENTION_HOURS : "168"
      KAFKA_CFG_NUM_PARTITIONS: "1"
      # The log directory is required for KRaft
      KAFKA_CFG_LOG_DIRS: "/tmp/kraft-storage"
      
  # ---------------------
  # 3. Kafka Connect (Debezium official)
  # ---------------------
  kafka-connect:
    image: confluentinc/cp-kafka-connect:latest
    container_name: kafka-connect
    depends_on:
      - kafka
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka:9092"
      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_CONFIG_STORAGE_TOPIC: "connect_configs"
      CONNECT_OFFSET_STORAGE_TOPIC: "connect_offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "connect_status"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/plugins"
    volumes:
      - ./plugins:/plugins

networks:
  default:
    name: fincore-notification_default

  # ---------------------
  # 4. Optional: Schema Registry (Confluent’s is the only one)
  # ---------------------
  # schema-registry:
  #   image: confluentinc/cp-schema-registry:7.5.0
  #   container_name: schema-registry
  #   depends_on:
  #     - kafka
  #   ports:
  #     - "8081:8081"
  #   environment:
  #     SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:9092
  #     SCHEMA_REGISTRY_HOST_NAME: schema-registry
  #     SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081














-----



{
    "name": "oracle-connector",
    "config": {
        "connector.class": "io.debezium.connector.oracle.OracleConnector",
        "tasks.max": "1",
        "database.hostname": "10.191.216.58",
        "database.port": "1522",
        "database.user": "ftwoahm",
        "database.password": "Password@123",
        "database.dbname": "crsprod",
        "database.sid": "crsprod",
        "database.server.name": "fincore",
        "table.include.list": "FINCORE.NOTIFICATION_TABLE",
        "database.history.kafka.bootstrap.servers": "kafka:9092",
        "database.history.kafka.topic": "schema-changes.oracle"
    }
}



-------------




        check.crcs = true
        client.dns.lookup = use_all_dns_ips
        client.id = connect-cluster-configs
        client.rack =
        connections.max.idle.ms = 540000
        default.api.timeout.ms = 60000
        enable.auto.commit = false
        enable.metrics.push = true
        exclude.internal.topics = true
        fetch.max.bytes = 52428800
        fetch.max.wait.ms = 500
        fetch.min.bytes = 1
        group.id = connect-cluster
        group.instance.id = null
        group.protocol = classic
        group.remote.assignor = null
        heartbeat.interval.ms = 3000
        interceptor.classes = []
        internal.leave.group.on.close = true
        internal.throw.on.fetch.stable.offset.unsupported = false
        isolation.level = read_uncommitted
        key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
        max.partition.fetch.bytes = 1048576
        max.poll.interval.ms = 300000
        max.poll.records = 500
        metadata.max.age.ms = 300000
        metadata.recovery.rebootstrap.trigger.ms = 300000
        metadata.recovery.strategy = rebootstrap
        metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
        metrics.num.samples = 2
        metrics.recording.level = INFO
        metrics.sample.window.ms = 30000
        partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
        receive.buffer.bytes = 65536
        reconnect.backoff.max.ms = 1000
        reconnect.backoff.ms = 50
        request.timeout.ms = 30000
        retry.backoff.max.ms = 1000
        retry.backoff.ms = 100
        sasl.client.callback.handler.class = null
        sasl.jaas.config = null
        sasl.kerberos.kinit.cmd = /usr/bin/kinit
        sasl.kerberos.min.time.before.relogin = 60000
        sasl.kerberos.service.name = null
        sasl.kerberos.ticket.renew.jitter = 0.05
        sasl.kerberos.ticket.renew.window.factor = 0.8
        sasl.login.callback.handler.class = null
        sasl.login.class = null
        sasl.login.connect.timeout.ms = null
        sasl.login.read.timeout.ms = null
        sasl.login.refresh.buffer.seconds = 300
        sasl.login.refresh.min.period.seconds = 60
        sasl.login.refresh.window.factor = 0.8
        sasl.login.refresh.window.jitter = 0.05
        sasl.login.retry.backoff.max.ms = 10000
        sasl.login.retry.backoff.ms = 100
        sasl.mechanism = GSSAPI
        sasl.oauthbearer.assertion.algorithm = RS256
        sasl.oauthbearer.assertion.claim.aud = null
        sasl.oauthbearer.assertion.claim.exp.seconds = 300
        sasl.oauthbearer.assertion.claim.iss = null
        sasl.oauthbearer.assertion.claim.jti.include = false
        sasl.oauthbearer.assertion.claim.nbf.seconds = 60
        sasl.oauthbearer.assertion.claim.sub = null
        sasl.oauthbearer.assertion.file = null
        sasl.oauthbearer.assertion.private.key.file = null
        sasl.oauthbearer.assertion.private.key.passphrase = null
        sasl.oauthbearer.assertion.template.file = null
        sasl.oauthbearer.client.credentials.client.id = null
        sasl.oauthbearer.client.credentials.client.secret = null
        sasl.oauthbearer.clock.skew.seconds = 30
        sasl.oauthbearer.expected.audience = null
        sasl.oauthbearer.expected.issuer = null
        sasl.oauthbearer.header.urlencode = false
        sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
        sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
        sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
        sasl.oauthbearer.jwks.endpoint.url = null
        sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
        sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
        sasl.oauthbearer.scope = null
        sasl.oauthbearer.scope.claim.name = scope
        sasl.oauthbearer.sub.claim.name = sub
        sasl.oauthbearer.token.endpoint.url = null
        security.protocol = PLAINTEXT
        security.providers = null
        send.buffer.bytes = 131072
        session.timeout.ms = 45000
        share.acknowledgement.mode = implicit
        socket.connection.setup.timeout.max.ms = 30000
        socket.connection.setup.timeout.ms = 10000
        ssl.cipher.suites = null
        ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
        ssl.endpoint.identification.algorithm = https
        ssl.engine.factory.class = null
        ssl.key.password = null
        ssl.keymanager.algorithm = SunX509
        ssl.keystore.certificate.chain = null
        ssl.keystore.key = null
        ssl.keystore.location = null
        ssl.keystore.password = null
        ssl.keystore.type = JKS
        ssl.protocol = TLSv1.3
        ssl.provider = null
        ssl.secure.random.implementation = null
        ssl.trustmanager.algorithm = PKIX
        ssl.truststore.certificates = null
        ssl.truststore.location = null
        ssl.truststore.password = null
        ssl.truststore.type = JKS
        value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.common.config.AbstractConfig)
[2025-11-03 11:11:02,149] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector)
[2025-11-03 11:11:02,152] INFO [Producer clientId=connect-cluster-configs] Cluster ID: 5L6g3nShT-eMCtK--X86sw (org.apache.kafka.clients.Metadata)
[2025-11-03 11:11:02,153] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, plugin.path, internal.key.converter.schemas.enable, config.storage.replication.factor, rest.port, internal.key.converter, metrics.context.connect.kafka.cluster.id, internal.value.converter.schemas.enable, status.storage.replication.factor, internal.value.converter, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-11-03 11:11:02,153] INFO Kafka version: 8.1.0-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2025-11-03 11:11:02,153] INFO Kafka commitId: ad96a4ab36bd815bac5069d4cc428d234a9f955a (org.apache.kafka.common.utils.AppInfoParser)
[2025-11-03 11:11:02,153] INFO Kafka startTimeMs: 1762168262153 (org.apache.kafka.common.utils.AppInfoParser)
[2025-11-03 11:11:02,157] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: 5L6g3nShT-eMCtK--X86sw (org.apache.kafka.clients.Metadata)
[2025-11-03 11:11:02,159] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect_configs-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-11-03 11:11:02,159] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to AutoOffsetResetStrategy{type=earliest} offset of partition connect_configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-11-03 11:11:02,168] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect_configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null isFenced: false)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-11-03 11:11:02,168] INFO Finished reading KafkaBasedLog for topic connect_configs (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-11-03 11:11:02,168] INFO Started KafkaBasedLog for topic connect_configs (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-11-03 11:11:02,168] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore)
[2025-11-03 11:11:02,174] INFO [Worker clientId=connect-kafka-connect:8083, groupId=connect-cluster] Cluster ID: 5L6g3nShT-eMCtK--X86sw (org.apache.kafka.clients.Metadata)












-----------------

E:\fincore-notification>docker ps
CONTAINER ID   IMAGE                                  COMMAND                  CREATED          STATUS                            PORTS                                         NAMES
7911e6a48b34   confluentinc/cp-kafka-connect:latest   "/etc/confluent/dock…"   12 minutes ago   Up 8 minutes (health: starting)   0.0.0.0:8083->8083/tcp, [::]:8083->8083/tcp   kafka-connect
e4b04acf75ec   apache/kafka:latest                    "/__cacert_entrypoin…"   12 minutes ago   Up 8 minutes                      0.0.0.0:9092->9092/tcp, [::]:9092->9092/tcp   kafka

E:\fincore-notification>




