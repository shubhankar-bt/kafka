package com.fincore.helpservice.config;

import dev.langchain4j.model.chat.ChatLanguageModel;
import dev.langchain4j.model.chat.StreamingChatLanguageModel;
import dev.langchain4j.model.embedding.EmbeddingModel;
import dev.langchain4j.model.ollama.OllamaChatModel;
import dev.langchain4j.model.ollama.OllamaStreamingChatModel;
import dev.langchain4j.model.ollama.OllamaEmbeddingModel;
import dev.langchain4j.store.embedding.EmbeddingStore;
import dev.langchain4j.store.embedding.redis.RedisEmbeddingStore;
import dev.langchain4j.data.segment.TextSegment;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Primary;

import java.time.Duration;
import java.util.Arrays;

@Configuration
public class AiConfiguration {

    @Value("${langchain4j.ollama.base-url}")
    private String ollamaBaseUrl;

    @Value("${langchain4j.ollama.chat-model.name}")
    private String chatModelName;

    @Value("${langchain4j.ollama.embedding-model.name}")
    private String embeddingModelName;

    @Value("${langchain4j.vector-store.redis.host}")
    private String redisHost;

    @Value("${langchain4j.vector-store.redis.port}")
    private Integer redisPort;

    @Value("${langchain4j.vector-store.redis.index-name}")
    private String indexName;

    @Value("${langchain4j.vector-store.redis.prefix}")
    private String prefix;

    @Value("${langchain4j.vector-store.redis.dimension:1024}")
    private Integer dimension;

    // The Standard Generative Model (Kept for background tasks if needed)
    @Bean
    public ChatLanguageModel chatLanguageModel() {
        return OllamaChatModel.builder()
                .baseUrl(ollamaBaseUrl)
                .modelName(chatModelName)
                .temperature(0.1)
                .numPredict(200)
                .timeout(Duration.ofSeconds(180))
                .maxRetries(1)
                .build();
    }

    // THE NEW STREAMING BEAN: Handles real-time token generation
    @Bean
    public StreamingChatLanguageModel streamingChatLanguageModel() {
        return OllamaStreamingChatModel.builder()
                .baseUrl(ollamaBaseUrl)
                .modelName(chatModelName)
                .temperature(0.1)
                .numPredict(200)
                .timeout(Duration.ofSeconds(180))
                .build();
    }

    // The Embedding Model (The Searcher)
    @Bean
    @Primary
    public EmbeddingModel embeddingModel() {
        return OllamaEmbeddingModel.builder()
                .baseUrl(ollamaBaseUrl)
                .modelName(embeddingModelName)
                .timeout(Duration.ofSeconds(15))
                .build();
    }

    // The Vector Database
    @Bean
    public EmbeddingStore<TextSegment> embeddingStore() {
        return RedisEmbeddingStore.builder()
                .host(redisHost)
                .port(redisPort)
                .dimension(dimension)
                .indexName(indexName)
                .prefix(prefix)
                .metadataKeys(Arrays.asList("permissionId", "actionLink", "actionLabel", "dataType"))
                .build();
    }
}



















package com.fincore.helpservice.controller;

import com.fincore.helpservice.dto.HelpRequestDTO;
import com.fincore.helpservice.service.FinCoreChatAgent;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.http.MediaType;
import org.springframework.web.bind.annotation.*;
import org.springframework.web.servlet.mvc.method.annotation.SseEmitter;

@RestController
@RequestMapping("/api/help")
@RequiredArgsConstructor
@Slf4j
public class HelpController {

    private final FinCoreChatAgent chatAgent;

    // Note the produces = MediaType.TEXT_EVENT_STREAM_VALUE
    @PostMapping(value = "/chat", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    public SseEmitter handleChatQuery(
            @RequestHeader("X-User-Id") String userId,
            @RequestHeader("X-Role-Id") String roleId,
            @RequestBody HelpRequestDTO request) {
        
        log.info("[API] Streaming Chat request received from User: {} | Role: {} | Message: '{}'", userId, roleId, request.getUserMessage());
        
        // Pass to the agent, which will return the active connection
        return chatAgent.handleStreamChat(userId, roleId, request.getUserMessage(), request.getCurrentScreen());
    }
}














package com.fincore.helpservice.service;

import com.fincore.helpservice.model.HelpFaqEntity;
import com.fincore.helpservice.model.HelpQuestionEntity;
import com.fincore.helpservice.repository.HelpFaqRepository;
import com.fincore.helpservice.repository.HelpQuestionRepository;
import com.github.benmanes.caffeine.cache.Cache;
import com.github.benmanes.caffeine.cache.Caffeine;
import dev.langchain4j.data.embedding.Embedding;
import dev.langchain4j.data.message.AiMessage;
import dev.langchain4j.data.message.ChatMessage;
import dev.langchain4j.data.message.SystemMessage;
import dev.langchain4j.data.message.UserMessage;
import dev.langchain4j.data.segment.TextSegment;
import dev.langchain4j.memory.ChatMemory;
import dev.langchain4j.memory.chat.MessageWindowChatMemory;
import dev.langchain4j.model.StreamingResponseHandler;
import dev.langchain4j.model.chat.StreamingChatLanguageModel;
import dev.langchain4j.model.embedding.EmbeddingModel;
import dev.langchain4j.model.output.Response;
import dev.langchain4j.store.embedding.EmbeddingMatch;
import dev.langchain4j.store.embedding.EmbeddingSearchRequest;
import dev.langchain4j.store.embedding.EmbeddingSearchResult;
import dev.langchain4j.store.embedding.EmbeddingStore;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;
import org.springframework.web.servlet.mvc.method.annotation.SseEmitter;

import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;

@Service
@RequiredArgsConstructor
@Slf4j
public class FinCoreChatAgent {

    private static final String FAILURE_MSG = "I cannot find this information in your authorized FinCore manuals. Please check your permissions or contact Fincore support.";

    private final StreamingChatLanguageModel streamingChatClient;
    private final EmbeddingModel embeddingModel;
    private final EmbeddingStore<TextSegment> vectorStore;
    private final PermissionService permissionService;
    private final ChatSessionService sessionService;
    private final HelpAnalyticsService analyticsService;
    private final HelpQuestionRepository questionRepository;
    private final HelpFaqRepository faqRepository;

    private final Cache<String, ChatMemory> userMemories = Caffeine.newBuilder()
            .expireAfterAccess(30, TimeUnit.MINUTES)
            .maximumSize(10000)
            .build();

    public SseEmitter handleStreamChat(String userId, String roleId, String userMessage, String currentScreen) {
        // Create an Emitter with a 3-minute timeout to allow heavy LLMs to think
        SseEmitter emitter = new SseEmitter(180000L);
        log.info("==================================================================");
        log.info("[AI-STREAM-INIT] User: {} | Msg: '{}'", userId, userMessage);

        try {
            // ========================================================================
            // 1. GUIDED MENUS (Fast DB Fetch - No LLM Needed)
            // ========================================================================
            if ("/action faq".equalsIgnoreCase(userMessage.trim())) {
                List<String> faqQuestions = faqRepository.findTop10ByIsActiveOrderByViewCountDesc("Y")
                        .stream().map(HelpFaqEntity::getQuestionText).collect(Collectors.toList());
                emitSuggestionAndClose(emitter, "Here are a few frequently asked questions:", faqQuestions);
                return emitter;
            }

            if (userMessage.trim().startsWith("/action module")) {
                String requestedScreen = userMessage.replace("/action module", "").trim();
                List<String> moduleQuestions = questionRepository.findByScreenNameAndIsActive(requestedScreen, "Y")
                        .stream().map(HelpQuestionEntity::getQuestionText).collect(Collectors.toList());

                if (moduleQuestions.isEmpty()) {
                    emitTextAndClose(emitter, "I don't have predefined questions for " + requestedScreen + " right now, but feel free to ask me anything about it!");
                } else {
                    emitSuggestionAndClose(emitter, "Here are a few common questions for the " + requestedScreen + " screen:", moduleQuestions);
                }
                return emitter;
            }

            // ========================================================================
            // 2. ESCALATION CHECK
            // ========================================================================
            if (sessionService.isEscalationRequired(userId)) {
                sessionService.resetStrikes(userId);
                emitEvent(emitter, "escalation", Map.of(
                        "botReply", "I seem to be having trouble helping you today. Would you like me to raise an IT Support Ticket with your chat history attached?"
                ));
                emitter.complete();
                return emitter;
            }

            // ========================================================================
            // 3. VECTOR DB FETCH & RBAC
            // ========================================================================
            List<String> allowedPerms = permissionService.getAllAllowedPermissionIdsForRole(roleId)
                    .stream().map(String::valueOf).collect(Collectors.toList());
            allowedPerms.add("GLOBAL");

            Embedding queryEmbedding = embeddingModel.embed(userMessage).content();
            EmbeddingSearchRequest searchRequest = EmbeddingSearchRequest.builder()
                    .queryEmbedding(queryEmbedding).maxResults(20).minScore(0.65).build();

            EmbeddingSearchResult<TextSegment> searchResult = vectorStore.search(searchRequest);
            
            List<EmbeddingMatch<TextSegment>> matches = searchResult.matches().stream()
                    .filter(match -> {
                        String docPerm = match.embedded().metadata().getString("permissionId");
                        return docPerm != null && allowedPerms.contains(docPerm);
                    })
                    .limit(2)
                    .toList();

            double highestScore = matches.isEmpty() ? 0.0 : matches.getFirst().score();

            // ========================================================================
            // 4. CONFIDENCE-BASED LINK ROUTING (Threshold: 0.80)
            // ========================================================================
            StringBuilder contextBuilder = new StringBuilder();
            String finalActionLink = null;
            String finalActionLabel = null;

            if (!matches.isEmpty()) {
                for (EmbeddingMatch<TextSegment> match : matches) {
                    contextBuilder.append("- ").append(match.embedded().text()).append("\n\n");
                    if (finalActionLink == null && highestScore >= 0.80) {
                        String link = match.embedded().metadata().getString("actionLink");
                        if (link != null && !"NONE".equals(link)) {
                            finalActionLink = link;
                            finalActionLabel = match.embedded().metadata().getString("actionLabel");
                        }
                    }
                }
            } else {
                contextBuilder.append("NO BANKING CONTEXT FOUND. Either the user lacks permission, or the knowledge does not exist.");
            }

            // Let the UI know we are about to start typing (Shows the "..." animation)
            emitEvent(emitter, "start", Map.of("status", "typing"));

            // ========================================================================
            // 5. PREPARE THE PROMPT & MEMORY
            // ========================================================================
            String liveEtlDate = permissionService.getLiveEtlDate();
            String currentTime = LocalDateTime.now().format(DateTimeFormatter.ofPattern("EEEE, MMMM dd, yyyy - hh:mm a"));
            String currentScreenContext = (currentScreen != null && !currentScreen.isEmpty()) ? currentScreen : "Unknown";

            String dynamicPrompt = """
                    You are the FinCore Smart Assistant, an advanced, highly capable AI banking bot built by Shubhankar, A Software Developer From Fincore Development Team.
                    Current Time: %s
                    System ETL Date: %s
                    User's Current Screen: %s
                    
                    <INSTRUCTIONS>
                    1. CASUAL CONVERSATION: If the user message is a greeting or small talk, respond warmly and dynamically. Do NOT mention banking context.
                    2. BANKING QUERIES: For FinCore questions, rely EXCLUSIVELY on the <AUTHORIZED_CONTEXT> below.
                    3. FORMATTING: Use standard Markdown formatting (**bold**, bullet points) for readability.
                    4. DIRECT ANSWERS: Answer immediately. Do NOT use conversational preambles like "Here is the information".
                    5. UNAUTHORIZED: If the <AUTHORIZED_CONTEXT> says "NO BANKING CONTEXT FOUND" or doesn't answer the query, output this exact phrase and NOTHING else:
                       %s
                    6. BE CONCISE: Keep your answers brief and direct.
                    </INSTRUCTIONS>
                    
                    <AUTHORIZED_CONTEXT>
                    %s
                    </AUTHORIZED_CONTEXT>
                    """.formatted(currentTime, liveEtlDate, currentScreenContext, FAILURE_MSG, contextBuilder.toString());

            ChatMemory memory = userMemories.get(userId, k -> MessageWindowChatMemory.withMaxMessages(3));
            memory.add(UserMessage.from(userMessage));

            List<ChatMessage> fullConversation = new ArrayList<>();
            fullConversation.add(SystemMessage.from(dynamicPrompt));
            fullConversation.addAll(memory.messages());

            // Needed for the async callbacks
            final String threadActionLink = finalActionLink;
            final String threadActionLabel = finalActionLabel;

            // ========================================================================
            // 6. ASYNC STREAMING ENGINE
            // ========================================================================
            streamingChatClient.generate(fullConversation, new StreamingResponseHandler<AiMessage>() {
                
                @Override
                public void onNext(String token) {
                    // Send each word to the UI the millisecond it is generated!
                    try {
                        emitEvent(emitter, "token", Map.of("token", token));
                    } catch (Exception e) {
                        log.warn("Client disconnected during streaming");
                        emitter.completeWithError(e);
                    }
                }

                @Override
                public void onComplete(Response<AiMessage> response) {
                    try {
                        String aiResponse = response.content().text().trim();
                        log.info("[AI-STREAM-COMPLETE] Successfully generated streaming response.");

                        // Background Cleanup & DB Logging
                        String intentLog = (highestScore < 0.80) ? "SMALL_TALK" : "ANSWERED";
                        Long successLogId = null;

                        if (aiResponse.contains("I cannot find this information") || aiResponse.contains(FAILURE_MSG)) {
                            sessionService.addStrikes(userId, 1);
                            successLogId = analyticsService.logChatInteraction(userId, "AI_RAG", userMessage, "NO_MATCH", (int) (highestScore * 100));
                            memory.add(AiMessage.from(FAILURE_MSG)); 
                            
                            // Send END event WITHOUT links because it failed
                            emitEvent(emitter, "end", Map.of("logId", successLogId, "status", "complete"));
                        } else {
                            sessionService.resetStrikes(userId);
                            successLogId = analyticsService.logChatInteraction(userId, "AI_RAG", userMessage, intentLog, (int) (highestScore * 100));
                            memory.add(response.content());
                            
                            // Send END event WITH Links to fade-in the buttons
                            Map<String, Object> endPayload = new java.util.HashMap<>(Map.of("logId", successLogId, "status", "complete"));
                            if (threadActionLink != null) {
                                endPayload.put("navigationLink", threadActionLink);
                                endPayload.put("navigationLabel", threadActionLabel);
                            }
                            emitEvent(emitter, "end", endPayload);
                        }
                        
                        emitter.complete();
                    } catch (Exception e) {
                        emitter.completeWithError(e);
                    }
                }

                @Override
                public void onError(Throwable error) {
                    log.error("[AI-STREAM-ERROR] LLM Streaming Failed", error);
                    try {
                        emitEvent(emitter, "error", Map.of("botReply", "I am currently experiencing a cognitive delay. Please try again."));
                        emitter.completeWithError(error);
                    } catch (Exception ignored) {}
                }
            });

        } catch (Exception e) {
            log.error("[AI-STREAM-ERROR] Critical Failure in Stream Setup", e);
            try {
                emitEvent(emitter, "error", Map.of("botReply", "An unexpected system error occurred."));
                emitter.completeWithError(e);
            } catch (Exception ignored) {}
        }
        
        return emitter;
    }

    // --- Helper Methods to easily send Server-Sent Events ---

    private void emitEvent(SseEmitter emitter, String eventName, Map<String, Object> data) throws Exception {
        emitter.send(SseEmitter.event().name(eventName).data(data));
    }

    private void emitSuggestionAndClose(SseEmitter emitter, String botReply, List<String> items) throws Exception {
        emitEvent(emitter, "suggestion", Map.of("botReply", botReply, "items", items));
        emitter.complete();
    }

    private void emitTextAndClose(SseEmitter emitter, String botReply) throws Exception {
        emitEvent(emitter, "text_reply", Map.of("botReply", botReply));
        emitter.complete();
    }
}


