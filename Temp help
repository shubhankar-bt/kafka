version: '3.8'
services:
  # 1. The Vector Database
  redis-vector:
    image: redis/redis-stack-server:latest
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  # 2. The Local AI Engine
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama

volumes:
  redis_data:
  ollama_data:

Crucial Setup Command:
After running docker-compose up -d, your containers will be running, but Ollama is "empty". You must tell Ollama to download the two models we chose. Run these two commands in your terminal:
 * docker exec -it ollama ollama run llama3 (Downloads the conversational brain - ~4.7GB)
 * docker exec -it ollama ollama pull mxbai-embed-large (Downloads the embedding search brain - ~670MB)
Step 2: Spring Boot Configuration (pom.xml & application.yml)
Add the official Spring AI dependencies to your pom.xml (Requires Spring Boot 3.2+ and Java 17+):
<!-- Spring AI BOM (Bill of Materials) -->
<dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>org.springframework.ai</groupId>
            <artifactId>spring-ai-bom</artifactId>
            <version>1.0.0-M1</version> <!-- Use the latest milestone or release -->
            <type>pom</type>
            <scope>import</scope>
        </dependency>
    </dependencies>
</dependencyManagement>

<dependencies>
    <!-- Connects to Ollama -->
    <dependency>
        <groupId>org.springframework.ai</groupId>
        <artifactId>spring-ai-ollama-spring-boot-starter</artifactId>
    </dependency>
    <!-- Connects to Redis Vector Store -->
    <dependency>
        <groupId>org.springframework.ai</groupId>
        <artifactId>spring-ai-redis-spring-boot-starter</artifactId>
    </dependency>
</dependencies>

Add this to your application.yml:
spring:
  ai:
    ollama:
      base-url: http://localhost:11434
      chat:
        model: llama3 # The talker
      embedding:
        model: mxbai-embed-large # The searcher
    vectorstore:
      redis:
        uri: redis://localhost:6379
        index: fincore-help-index
        prefix: "fincore:doc:"

















package com.fincore.helpservice.service;

import com.fincore.helpservice.model.HelpQuestionEntity;
import com.fincore.helpservice.repository.HelpQuestionRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.ai.document.Document;
import org.springframework.ai.vectorstore.VectorStore;
import org.springframework.boot.context.event.ApplicationReadyEvent;
import org.springframework.context.event.EventListener;
import org.springframework.stereotype.Service;

import java.util.List;
import java.util.Map;
import java.util.stream.Collectors;

/**
 * Handles converting Oracle DB text into AI Mathematical Vectors (Embeddings)
 * and storing them securely in Redis Stack with RBAC metadata.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class DocumentIngestionService {

    private final HelpQuestionRepository questionRepository;
    private final VectorStore vectorStore; // Spring AI Redis Auto-Configuration

    @EventListener(ApplicationReadyEvent.class)
    public void ingestKnowledgeBase() {
        log.info("Starting AI Knowledge Ingestion to Redis...");

        List<HelpQuestionEntity> questions = questionRepository.findByIsActive("Y");

        List<Document> documents = questions.stream().map(q -> {
            // 1. Combine Question and Answer so the AI has full context
            String content = "Q: " + q.getQuestionText() + "\nA: " + q.getAnswerContent();
            if (q.getProTip() != null) {
                content += "\nPro Tip: " + q.getProTip();
            }

            // 2. Attach Security Metadata (CRITICAL FOR RBAC)
            // We store the Permission ID as a String for Redis filtering compatibility
            String permId = q.getPermissionId() != null ? String.valueOf(q.getPermissionId()) : "GLOBAL";
            
            Map<String, Object> metadata = Map.of(
                    "permissionId", permId,
                    "screenName", q.getScreenName() != null ? q.getScreenName() : "General",
                    "actionLink", q.getActionLink() != null ? q.getActionLink() : "NONE",
                    "actionLabel", q.getActionLabel() != null ? q.getActionLabel() : "NONE"
            );

            // 3. Create Spring AI Document
            return new Document(content, metadata);
        }).collect(Collectors.toList());

        // 4. Send to Ollama (Embed) -> Save to Redis (Store)
        // Note: In production, we would check if docs already exist to avoid re-embedding.
        if (!documents.isEmpty()) {
            vectorStore.add(documents);
            log.info("Successfully ingested {} documents into Redis Vector Store.", documents.size());
        }
    }
}














package com.fincore.helpservice.service;

import com.fincore.helpservice.dto.HelpResponseDTO;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.ai.chat.client.ChatClient;
import org.springframework.ai.chat.client.advisor.MessageChatMemoryAdvisor;
import org.springframework.ai.chat.client.advisor.QuestionAnswerAdvisor;
import org.springframework.ai.chat.memory.InMemoryChatMemory;
import org.springframework.ai.document.Document;
import org.springframework.ai.vectorstore.SearchRequest;
import org.springframework.ai.vectorstore.VectorStore;
import org.springframework.ai.vectorstore.filter.FilterExpressionBuilder;
import org.springframework.stereotype.Service;

import java.util.List;
import java.util.stream.Collectors;

/**
 * THE RAG ENGINE (Retrieval-Augmented Generation)
 * The ultimate fusion of Vector Search, RBAC Security, and LLM Generation.
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class FinCoreChatAgent {

    private final ChatClient chatClient; // Configured automatically by Spring AI
    private final VectorStore vectorStore;
    private final PermissionService permissionService;
    
    // In-Memory Chat History (Conversational Context)
    // Production: Use RedisChatMemory (custom implementation) for multi-node persistence
    private final InMemoryChatMemory chatMemory = new InMemoryChatMemory();

    private static final String SYSTEM_PROMPT = """
            You are the elite FinCore Banking Assistant. 
            You must ONLY answer using the EXACT Context provided below. 
            Do NOT hallucinate, guess, or provide information from outside the Context.
            If the Context does not contain the answer, reply EXACTLY with: 
            'I cannot find this information in your currently authorized FinCore manuals. Please check your permissions or contact IT.'
            Always format your response cleanly using HTML tags like <br/> or <b> for the frontend UI.
            """;

    public FinCoreChatAgent(ChatClient.Builder chatClientBuilder, VectorStore vectorStore, PermissionService permissionService) {
        this.vectorStore = vectorStore;
        this.permissionService = permissionService;
        
        // Build the core Chat Client with our strict System Guardrails
        this.chatClient = chatClientBuilder
                .defaultSystem(SYSTEM_PROMPT)
                .build();
    }

    public HelpResponseDTO handleChat(String userId, String roleId, String userMessage) {
        try {
            // 1. Get User's Allowed Permissions (e.g., [5, 6, 12, 30])
            List<String> allowedPermIds = permissionService.getAllAllowedPermissionIdsForRole(roleId)
                    .stream()
                    .map(String::valueOf)
                    .collect(Collectors.toList());
            allowedPermIds.add("GLOBAL"); // Add global FAQs

            // 2. Build RBAC Vector Search Request
            // This ensures Redis ONLY returns paragraphs the user is allowed to read!
            var filterBuilder = new FilterExpressionBuilder();
            SearchRequest searchRequest = SearchRequest.query(userMessage)
                    .withTopK(3) // Fetch top 3 matches
                    .withFilterExpression(filterBuilder.in("permissionId", allowedPermIds).build());

            // 3. Pre-fetch documents to extract UI Action Links (Solving Gap 2)
            List<Document> matchedDocs = vectorStore.similaritySearch(searchRequest);
            String primaryActionLink = null;
            String primaryActionLabel = null;
            
            if (!matchedDocs.isEmpty()) {
                // Grab the link from the highest confidence document
                Document topDoc = matchedDocs.get(0);
                if (!"NONE".equals(topDoc.getMetadata().get("actionLink"))) {
                    primaryActionLink = (String) topDoc.getMetadata().get("actionLink");
                    primaryActionLabel = (String) topDoc.getMetadata().get("actionLabel");
                }
            }

            // 4. Call Llama 3 with Memory and RAG Advisors
            String aiResponse = this.chatClient.prompt()
                    .user(userMessage)
                    .advisors(
                            // Advisor 1: RAG (I injects the Redis search results into the prompt securely)
                            new QuestionAnswerAdvisor(vectorStore, searchRequest),
                            // Advisor 2: Memory (It remembers previous messages using the userId as a session key)
                            new MessageChatMemoryAdvisor(chatMemory, userId, 5) // Remembers last 5 messages
                    )
                    .call()
                    .content();

            // 5. Construct final DTO to send to frontend
            return HelpResponseDTO.builder()
                    .responseType("TEXT_REPLY")
                    .botReply(aiResponse)
                    .navigationLink(primaryActionLink)   // Restores the UI button!
                    .navigationLabel(primaryActionLabel)
                    .build();

        } catch (Exception e) {
            log.error("AI Generation Failed", e);
            return HelpResponseDTO.builder()
                    .responseType("TEXT_REPLY")
                    .botReply("I am currently experiencing a cognitive delay. Please try again in a moment.")
                    .build();
        }
    }
}



















