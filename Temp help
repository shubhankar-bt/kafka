package com.fincore.helpservice.service;

import com.fincore.helpservice.dto.HelpResponseDTO;
import com.fincore.helpservice.model.HelpFaqEntity;
import com.fincore.helpservice.model.HelpQuestionEntity;
import com.fincore.helpservice.repository.HelpFaqRepository;
import com.fincore.helpservice.repository.HelpQuestionRepository;
import com.github.benmanes.caffeine.cache.Cache;
import com.github.benmanes.caffeine.cache.Caffeine;
import dev.langchain4j.data.embedding.Embedding;
import dev.langchain4j.data.message.AiMessage;
import dev.langchain4j.data.message.SystemMessage;
import dev.langchain4j.data.message.UserMessage;
import dev.langchain4j.data.segment.TextSegment;
import dev.langchain4j.memory.ChatMemory;
import dev.langchain4j.memory.chat.MessageWindowChatMemory;
import dev.langchain4j.model.chat.ChatLanguageModel;
import dev.langchain4j.model.embedding.EmbeddingModel;
import dev.langchain4j.store.embedding.EmbeddingMatch;
import dev.langchain4j.store.embedding.EmbeddingSearchRequest;
import dev.langchain4j.store.embedding.EmbeddingSearchResult;
import dev.langchain4j.store.embedding.EmbeddingStore;
import jakarta.annotation.PostConstruct;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;

import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;
import java.util.List;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;

/**
 * THE RAG ENGINE (LangChain4j Implementation)
 * Orchestrates Vector Search, Dynamic Prompting, and Generative AI (Phi-3).
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class FinCoreChatAgent {

    private static final String FAILURE_MSG = "I cannot find this information in your authorized FinCore manuals. Please check your permissions or contact IT.";
    private final ChatLanguageModel chatClient;
    private final EmbeddingModel embeddingModel;
    private final EmbeddingStore<TextSegment> vectorStore;
    private final PermissionService permissionService;
    private final ChatSessionService sessionService;
    private final HelpAnalyticsService analyticsService;
    private final HelpQuestionRepository questionRepository;
    private final HelpFaqRepository faqRepository;
    // Session-based Chat Memory (Sessions expire after 30 minutes of inactivity.)
    private final Cache<String, ChatMemory> userMemories = Caffeine.newBuilder()
            .expireAfterAccess(30, TimeUnit.MINUTES)
            .maximumSize(10000) // Max 10,000 concurrent active chat sessions
            .build();
    // Add this variable near the top of your class
    private Embedding smallTalkAnchor;

    // Run this once when Spring Boot starts
    @PostConstruct
    public void initSemanticRouter() {
        log.info("[SEMANTIC-ROUTER] Initializing Small Talk mathematical anchor...");
        // We define the pure concept of small talk.
        String smallTalkConcept = "hello hi hey greetings good morning good afternoon what is up whats up how are you doing who are you thank you thanks";
        this.smallTalkAnchor = embeddingModel.embed(smallTalkConcept).content();
    }

    public HelpResponseDTO handleChat(String userId, String roleId, String userMessage, String currentScreen) {
        log.info("[AI-CHAT] Processing query for User: {}", userId);

        try {
            // ========================================================================
            // 0. GUIDED MENUS (System Slash Commands)
            // ========================================================================
            if ("/action faq".equalsIgnoreCase(userMessage.trim())) {
                List<String> faqQuestions = faqRepository.findTop10ByIsActiveOrderByViewCountDesc("Y")
                        .stream().map(HelpFaqEntity::getQuestionText).collect(Collectors.toList());

                return HelpResponseDTO.builder()
                        .responseType("SUGGESTION")
                        .botReply("Here are a few frequently asked questions:")
                        .items(faqQuestions)
                        .build();
            }

            if (userMessage.trim().startsWith("/action module")) {
                String requestedScreen = userMessage.replace("/action module", "").trim();
                List<String> moduleQuestions = questionRepository.findByScreenNameAndIsActive(requestedScreen, "Y")
                        .stream().map(HelpQuestionEntity::getQuestionText).collect(Collectors.toList());

                if (moduleQuestions.isEmpty()) {
                    return HelpResponseDTO.builder()
                            .responseType("TEXT_REPLY")
                            .botReply("I don't have predefined questions for " + requestedScreen + ", but feel free to ask me anything about it!")
                            .build();
                }

                return HelpResponseDTO.builder()
                        .responseType("SUGGESTION")
                        .botReply("Here are a few common questions for " + requestedScreen + ":")
                        .items(moduleQuestions)
                        .build();
            }

            // ========================================================================
            // 1. RAG AI PIPELINE (For regular typed questions or clicked suggestions)
            // ========================================================================

            // ==========================================
            // 2. QUERY PRE-CLEANING (Noise Reduction)
            // ==========================================
            String cleanedQuery = userMessage
                    .replaceAll("(?i)\\b(hi|hello|hey|greetings|dear)\\b", "")
                    .replaceAll("[^a-zA-Z0-9\\s?]", "") // Remove weird special characters, keep question marks
                    .trim();

            log.debug("[AI-CHAT] Original: '{}' | Cleaned: '{}'", userMessage, cleanedQuery);


            // 1. ESCALATION CHECK
            if (sessionService.isEscalationRequired(userId)) {
                log.warn("[AI-CHAT] User {} requires IT escalation.", userId);
                sessionService.resetStrikes(userId);
                return HelpResponseDTO.builder()
                        .responseType("ESCALATION_OFFER")
                        .botReply("I seem to be having trouble helping you today. Would you like me to raise an IT Support Ticket with your chat history attached?")
                        .build();
            }

            // ==========================================
            // 4. VECTOR SEARCH WITH HARD THRESHOLD
            // ==========================================
            List<String> allowedPerms = permissionService.getAllAllowedPermissionIdsForRole(roleId)
                    .stream().map(String::valueOf).collect(Collectors.toList());
            allowedPerms.add("GLOBAL");

            String enhancedSearchQuery = cleanedQuery;
            if (currentScreen != null && !currentScreen.isEmpty()) {
                enhancedSearchQuery = cleanedQuery + " regarding the " + currentScreen + " screen.";
            }

            // 3. EXECUTE SECURE VECTOR SEARCH
            // Convert user text to vector using mxbai
            Embedding queryEmbedding = embeddingModel.embed(userMessage).content();

            EmbeddingSearchRequest searchRequest = EmbeddingSearchRequest.builder()
                    .queryEmbedding(queryEmbedding)
                    .maxResults(30)
                    .minScore(0.45) // Lowered to 0.45. We let the LLM do the final filtering.
                    .build();

            EmbeddingSearchResult<TextSegment> searchResult = vectorStore.search(searchRequest);

            // Stream Filter & Track Highest Confidence Score
            double highestScore = 0.0;
            List<EmbeddingMatch<TextSegment>> matches = searchResult.matches().stream()
                    .filter(match -> allowedPerms.contains(match.embedded().metadata().getString("permissionId")))
                    .limit(3)
                    .collect(Collectors.toList());

            if (!matches.isEmpty()) {
                highestScore = matches.get(0).score(); // Capture confidence for analytics!
            }

            // ==========================================
            // 5. DETERMINISTIC GUARD (Bypass LLM entirely!)
            // ==========================================
            if (matches.isEmpty()) {
                log.info("[AI-CHAT] No context found. Applying Hybrid Router.");

                // We pass the mathematical vector of what the user typed into our NLP classifier
                // Pass BOTH the cleaned string and the mathematical vector
                if (isSmallTalk(userMessage, queryEmbedding)) {
                    Long logId = analyticsService.logChatInteraction(userId, "JAVA_ROUTER", userMessage, "SMALL_TALK", 100);
                    return HelpResponseDTO.builder()
                            .responseType("TEXT_REPLY")
                            .botReply("Hello! I am the FinCore Smart Assistant developed by Shubhankar. How can I help you with your banking needs today?")
                            .logId(logId)
                            .build();
                }

                // If it is NOT small talk, and NOT in the database -> Fast Fail
                sessionService.addStrikes(userId, 1);
                Long failLogId = analyticsService.logChatInteraction(userId, "SEMANTIC_ROUTER", userMessage, "NO_MATCH", 0);
                return HelpResponseDTO.builder()
                        .responseType("NO_MATCH")
                        .botReply(FAILURE_MSG)
                        .logId(failLogId)
                        .build();
            }


            // ==========================================
            // 6. GENERATIVE AI EXECUTION
            // ==========================================
            StringBuilder contextBuilder = new StringBuilder();
            String primaryActionLink = null;
            String primaryActionLabel = null;

            for (EmbeddingMatch<TextSegment> match : matches) {
                contextBuilder.append("- ").append(match.embedded().text()).append("\n\n");
                if (primaryActionLink == null) {
                    String link = match.embedded().metadata().getString("actionLink");
                    if (!"NONE".equals(link)) {
                        primaryActionLink = link;
                        primaryActionLabel = match.embedded().metadata().getString("actionLabel");
                    }
                }
            }

            // 5. DYNAMIC PROMPT INJECTION
            String liveEtlDate = permissionService.getLiveEtlDate();
            String currentTime = LocalDateTime.now().format(DateTimeFormatter.ofPattern("EEEE, MMMM dd, yyyy - hh:mm a"));
            String currentScreenContext = (currentScreen != null && !currentScreen.isEmpty()) ? currentScreen : "Unknown";

            // We inject the Screen Context here so the LLM knows it, without ruining the mathematical search!
            String dynamicPrompt = """
                     You are the FinCore Smart Assistant, an AI banking bot.
                     Current Time: %s
                     System ETL Date: %s
                     User's Current Screen: %s
                    
                     RULES:
                     1. Answer the user's question using ONLY the [BANKING CONTEXT] below.
                     2. Be direct, professional, and use HTML tags like <b> for formatting.
                     3. Do NOT explain your thought process.
                     4. If the context does not fully answer the question, reply EXACTLY: '%s'
                    
                    [BANKING CONTEXT]
                     %s
                    """.formatted(currentTime, liveEtlDate, currentScreenContext, FAILURE_MSG, contextBuilder.toString());

            ChatMemory memory = userMemories.get(userId, k -> MessageWindowChatMemory.withMaxMessages(5));
            memory.add(UserMessage.from(userMessage));

            log.info("[AI-CHAT] Sending Context to Phi-3 LLM. Confidence Score: {}", highestScore);
            AiMessage responseMessage = chatClient.generate(
                    SystemMessage.from(dynamicPrompt),
                    memory.messages().get(memory.messages().size() - 1)
            ).content();

            String aiResponse = responseMessage.text();

            if (aiResponse.contains("I cannot find this information") || aiResponse.contains(FAILURE_MSG)) {
                sessionService.addStrikes(userId, 1);
                Long failLogId = analyticsService.logChatInteraction(userId, "AI_RAG", userMessage, "NO_MATCH", (int) (highestScore * 100));
                memory.add(AiMessage.from(FAILURE_MSG));
                return HelpResponseDTO.builder().responseType("NO_MATCH").botReply(FAILURE_MSG).logId(failLogId).build();
            }

            sessionService.resetStrikes(userId);
            memory.add(responseMessage);

            // Pass the Redis Math Score to your Database Analytics!
            Long successLogId = analyticsService.logChatInteraction(userId, "AI_RAG", userMessage, "ANSWERED", (int) (highestScore * 100));

            return HelpResponseDTO.builder()
                    .responseType("TEXT_REPLY")
                    .botReply(aiResponse.trim())
                    .navigationLink(primaryActionLink)
                    .navigationLabel(primaryActionLabel)
                    .logId(successLogId)
                    .build();

        } catch (Exception e) {
            log.error("[AI-CHAT] Critical AI Generation Failure", e);
            return HelpResponseDTO.builder()
                    .responseType("TEXT_REPLY")
                    .botReply("I am currently experiencing a cognitive delay. Please try again in a moment.")
                    .build();
        }
    }

    /**
     * HYBRID INTENT CLASSIFIER
     * Uses Regex mxbai-embed-large to mathematically compare the user's sentence
     * against the concept of "Small Talk".
     */
    private boolean isSmallTalk(String userMessage, Embedding userEmbedding) {
        String q = userMessage.toLowerCase().trim();
        if (q.isEmpty()) return true;

        // Expanded Regex: Catches hi, hii, hiii, hey, heyy, and common questions.
        if (q.matches(".*\\b(how are you|who are you|who built you|what is your name|what time is it|thanks|thank you|hello|hi+|hey+|greetings)\\b.*")) {
            log.info("[ROUTER] Caught by Regex.");
            return true;
        }

        float[] vectorA = userEmbedding.vector();
        float[] vectorB = this.smallTalkAnchor.vector();
        double dotProduct = 0.0, normA = 0.0, normB = 0.0;

        for (int i = 0; i < vectorA.length; i++) {
            dotProduct += vectorA[i] * vectorB[i];
            normA += vectorA[i] * vectorA[i];
            normB += vectorB[i] * vectorB[i];
        }

        double cosineSimilarity = dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
        log.info("[ROUTER] Semantic Score: {}%", (int) (cosineSimilarity * 100));

        // Dropped to 0.65 to be slightly more forgiving of typos
        return cosineSimilarity > 0.65;
    }

    public void incrementFaqPopularity(String questionText) {
        faqRepository.findByQuestionTextAndIsActive(questionText, "Y").ifPresent(faq -> {
            faq.setViewCount(faq.getViewCount() + 1);
            faqRepository.save(faq);
        });
    }
}















tests :



{
   "userMessage": "What is segment"
}

ans :
{
    "responseType": "NO_MATCH",
    "botReply": "I cannot find this information in your authorized FinCore manuals. Please check your permissions or contact IT.",
    "navigationLink": null,
    "navigationLabel": null,
    "logId": 51,
    "items": null
}



log:
2026-02-25 15:06:12.229 INFO  [http-nio-9099-exec-7] c.f.h.c.HelpController: [API] Chat request received from User: 2488766 | Role: 51 | Message: 'What is segment' 
2026-02-25 15:06:12.777 INFO  [http-nio-9099-exec-7] c.f.h.s.FinCoreChatAgent: [AI-CHAT] Processing query for User: 2488766 
2026-02-25 15:06:13.016 INFO  [http-nio-9099-exec-7] c.f.h.s.FinCoreChatAgent: [AI-CHAT] No context found. Applying Hybrid Router. 
2026-02-25 15:06:13.017 INFO  [http-nio-9099-exec-7] c.f.h.s.FinCoreChatAgent: [ROUTER] Semantic Score: 38% 
2026-02-25 15:06:13.017 WARN  [http-nio-9099-exec-7] c.f.h.s.ChatSessionService: [SESSION] User 2488766 gained a strike. Current strikes: 2/3 





{
   "userMessage": "Can i create cgl ?"
}

{
    "responseType": "NO_MATCH",
    "botReply": "I cannot find this information in your authorized FinCore manuals. Please check your permissions or contact IT.",
    "navigationLink": null,
    "navigationLabel": null,
    "logId": 52,
    "items": null
}

log:

2026-02-25 15:07:05.240 INFO  [http-nio-9099-exec-8] c.f.h.c.HelpController: [API] Chat request received from User: 2488766 | Role: 51 | Message: 'Can i create cgl ?' 
2026-02-25 15:07:05.241 INFO  [http-nio-9099-exec-8] c.f.h.s.FinCoreChatAgent: [AI-CHAT] Processing query for User: 2488766 
2026-02-25 15:07:05.467 INFO  [http-nio-9099-exec-8] c.f.h.s.FinCoreChatAgent: [AI-CHAT] No context found. Applying Hybrid Router. 
2026-02-25 15:07:05.468 INFO  [http-nio-9099-exec-8] c.f.h.s.FinCoreChatAgent: [ROUTER] Semantic Score: 30% 
2026-02-25 15:07:05.469 WARN  [http-nio-9099-exec-8] c.f.h.s.ChatSessionService: [SESSION] User 2488766 gained a strike. Current strikes: 3/3 



{
   "userMessage": "How are you today?"
}

{
    "responseType": "ESCALATION_OFFER",
    "botReply": "I seem to be having trouble helping you today. Would you like me to raise an IT Support Ticket with your chat history attached?",
    "navigationLink": null,
    "navigationLabel": null,
    "logId": null,
    "items": null
}


2026-02-25 15:08:22.871 INFO  [http-nio-9099-exec-10] c.f.h.c.HelpController: [API] Chat request received from User: 2488766 | Role: 51 | Message: 'How are you today?' 
2026-02-25 15:08:23.408 INFO  [http-nio-9099-exec-10] c.f.h.s.FinCoreChatAgent: [AI-CHAT] Processing query for User: 2488766 
2026-02-25 15:08:23.408 WARN  [http-nio-9099-exec-10] c.f.h.s.FinCoreChatAgent: [AI-CHAT] User 2488766 requires IT escalation. 





{
   "userMessage": "Whats up?"
}

{
    "responseType": "TEXT_REPLY",
    "botReply": "Hello! I am the FinCore Smart Assistant developed by Shubhankar. How can I help you with your banking needs today?",
    "navigationLink": null,
    "navigationLabel": null,
    "logId": 53,
    "items": null
}
log :
2026-02-25 15:09:04.933 INFO  [http-nio-9099-exec-1] c.f.h.c.HelpController: [API] Chat request received from User: 2488766 | Role: 51 | Message: 'Whats up?' 
2026-02-25 15:09:04.934 INFO  [http-nio-9099-exec-1] c.f.h.s.FinCoreChatAgent: [AI-CHAT] Processing query for User: 2488766 
2026-02-25 15:09:05.163 INFO  [http-nio-9099-exec-1] c.f.h.s.FinCoreChatAgent: [AI-CHAT] No context found. Applying Hybrid Router. 
2026-02-25 15:09:05.163 INFO  [http-nio-9099-exec-1] c.f.h.s.FinCoreChatAgent: [ROUTER] Semantic Score: 80% 


my view :  may be regex catch is fine but it should not be the answer of wahtsup. when i ask whatsup it should reply something relatable which should sound i am good, what about you. 




{
   "userMessage": "What is the full form of cgl?"
}

{
    "responseType": "NO_MATCH",
    "botReply": "I cannot find this information in your authorized FinCore manuals. Please check your permissions or contact IT.",
    "navigationLink": null,
    "navigationLabel": null,
    "logId": 54,
    "items": null
}

log :

2026-02-25 15:11:10.233 INFO  [http-nio-9099-exec-3] c.f.h.c.HelpController: [API] Chat request received from User: 2488766 | Role: 51 | Message: 'What is the full form of cgl?' 
2026-02-25 15:11:10.769 INFO  [http-nio-9099-exec-3] c.f.h.s.FinCoreChatAgent: [AI-CHAT] Processing query for User: 2488766 
2026-02-25 15:11:10.992 INFO  [http-nio-9099-exec-3] c.f.h.s.FinCoreChatAgent: [AI-CHAT] No context found. Applying Hybrid Router. 
2026-02-25 15:11:10.992 INFO  [http-nio-9099-exec-3] c.f.h.s.FinCoreChatAgent: [ROUTER] Semantic Score: 36% 
2026-02-25 15:11:10.993 WARN  [http-nio-9099-exec-3] c.f.h.s.ChatSessionService: [SESSION] User 2488766 gained a strike. Current strikes: 1/3 




{
   "userMessage": "What is the lifecyle of cgl?"
}



{
    "responseType": "NO_MATCH",
    "botReply": "I cannot find this information in your authorized FinCore manuals. Please check your permissions or contact IT.",
    "navigationLink": null,
    "navigationLabel": null,
    "logId": 55,
    "items": null
}


logs : 
2026-02-25 15:14:48.437 INFO  [http-nio-9099-exec-5] c.f.h.c.HelpController: [API] Chat request received from User: 2488766 | Role: 51 | Message: 'What is the lifecyle of cgl?' 
2026-02-25 15:14:48.991 INFO  [http-nio-9099-exec-5] c.f.h.s.FinCoreChatAgent: [AI-CHAT] Processing query for User: 2488766 
2026-02-25 15:14:49.243 INFO  [http-nio-9099-exec-5] c.f.h.s.FinCoreChatAgent: [AI-CHAT] No context found. Applying Hybrid Router. 
2026-02-25 15:14:49.245 INFO  [http-nio-9099-exec-5] c.f.h.s.FinCoreChatAgent: [ROUTER] Semantic Score: 34% 
2026-02-25 15:14:49.246 WARN  [http-nio-9099-exec-5] c.f.h.s.ChatSessionService: [SESSION] User 2488766 gained a strike. Current strikes: 2/3 














nothing is working, bot is not able to answer anything, my role is 51.
51 has belowm permissions, still it can not give amswer. Also regarding cgl we have knowledge base master which is global that is also not working. 
global data for cgl knowledge: 
1	CGL Maker-Checker Lifecycle	In the FinCore system, Central General Ledgers (CGLs) are governed by a strict Maker-Checker protocol. A user with "Manage CGLs" access (The Maker) can create or modify a CGL. However, the CGL does not become active immediately. It must be reviewed by a different user with "CGL Requests" access (The Checker). The Checker can either approve or reject the modification.		Y


{1
2
5
6
7
8
9
10
12
13
14
15
16
17
18
19
20
21
22}










